# Wiki RAG (База знаний)

Система контекстного поиска по документации с автоматической инжекцией в системный промпт LLM.

## Скриншот

<!-- Вставьте скриншот страницы Wiki RAG -->
![Wiki RAG](images/wiki-rag.png)

## Концепция

Wiki RAG — это двухуровневая поисковая система по markdown-документам, встроенная в ИИ-секретаря:
- **Semantic Embeddings** (если доступен провайдер) — понимает смысл: «сколько стоит» → находит «тарифы и цены»
- **BM25 Okapi** (всегда доступен) — морфологический поиск с русским/английским стеммингом
- Автоматически индексирует все файлы `.md` из каталога `wiki-pages/`
- Разбивает документы на секции по заголовкам `##` и `###`
- При запросе к LLM автоматически инжектит релевантные секции документации в системный промпт
- **Минимальные зависимости** — BM25 работает без GPU и без внешних API

## Как это работает

### Индексация

```
1. Парсинг markdown по заголовкам ## и ###
2. Токенизация текста (Unicode-aware, русский + английский)
3. Стемминг: "настройки" → "настройк", "settings" → "set"
4. Фильтрация стоп-слов (русские + английские)
5. Построение BM25 индекса (document frequency, avg doc length)
6. Токены из заголовков получают 4x вес
```

### Фильтрация

| Параметр | Значение |
|----------|----------|
| **MIN_TOKEN_LEN** | 2 символа |
| **MIN_SCORE** | 0.5 (порог минимальной релевантности) |
| **Минимальная длина секции** | 50 символов (короткие игнорируются) |
| **Стоп-слова** | Фильтруются для русского и английского |

### Поиск (двухуровневый)

```
1. Пользователь отправляет запрос LLM
2. Если доступны embeddings:
   a. Эмбеддинг запроса через провайдер
   b. Cosine similarity по всем секциям
   c. Топ-k секций (similarity > 0.3)
3. Если embeddings нет или не нашли — BM25 fallback:
   a. Токенизация + стемминг запроса
   b. BM25 Okapi ранжирование → топ-k (score ≥ 0.5)
4. Форматирование в markdown-контекст
5. Инжекция в начало системного промпта
6. LLM отвечает с учётом найденной документации
```

### BM25 Okapi

BM25 — это алгоритм ранжирования, улучшающий TF-IDF за счёт:
- **Насыщение TF** (k1=1.5) — 10-е повторение слова не так важно, как 1-е
- **Нормализация по длине** (b=0.75) — короткие точные секции не проигрывают длинным
- **Стемминг** — "настройки", "настройка", "настроить" → одна основа "настройк"

### Semantic Embeddings

Поверх BM25 работает семантический поиск на основе embedding-векторов:

| Провайдер | Модель | Размерность | Когда используется |
|-----------|--------|-------------|-------------------|
| **Local** (sentence-transformers) | paraphrase-multilingual-MiniLM-L12-v2 | 384 | `DEPLOYMENT_MODE=full` + пакет установлен |
| **Gemini** | text-embedding-004 | 768 | Облачный LLM = Gemini |
| **OpenAI-compatible** | text-embedding-3-small | varies | Облачный LLM = OpenAI/DeepSeek/etc |

**Приоритет:** Local → Cloud → BM25 fallback

Эмбеддинги кэшируются в `data/wiki_embeddings.json` (~1.7MB для 573 секций). При перезапуске загружаются из кэша без повторного вычисления.

## Управление документами

Левая панель отображает все документы в базе:

| Элемент | Описание |
|---------|----------|
| **Название** | Имя файла или title из метаданных |
| **Секций** | Количество индексированных секций |
| **Токенов** | Уникальные токены |
| **Источник** | `source_file` (относительный путь) |
| **Действия** | Просмотр / Редактировать / Удалить |

### Загрузка документа

1. Нажмите **"Загрузить документ"**
2. Выберите файл `.md` или `.txt`
3. Документ сохраняется в `wiki-pages/` и индексируется автоматически

### Синхронизация с диском

При первом обращении к API система автоматически сканирует `wiki-pages/`:
- Новые файлы на диске → добавляются в БД
- Файлы в БД, но отсутствующие на диске → помечаются как недоступные
- Изменённые файлы (по timestamp) → переиндексируются

### Редактирование

1. Выберите документ из списка
2. Откройте редактор (markdown)
3. Сохраните — индекс обновится автоматически

### Удаление

Удаление документа:
- **Из БД** — запись удаляется
- **С диска** — файл удаляется физически из `wiki-pages/`

## Поиск и контекст

### Поиск (Search)

API: `POST /admin/wiki-rag/search`

```json
{
  "query": "как настроить telegram бота",
  "top_k": 5
}
```

Результат:

```json
{
  "results": [
    {
      "title": "Настройка воронки в боте",
      "body": "Основная конфигурация происходит в Telegram → [Бот] → Sales.",
      "source_file": "Sales",
      "score": 8.141
    }
  ],
  "query": "как настроить telegram бота"
}
```

### Контекст (Retrieve)

API: `POST /admin/wiki-rag/retrieve`

```json
{
  "query": "telegram webhook",
  "max_chars": 2500
}
```

Возвращает отформатированный markdown-контекст для инжекции в системный промпт:

```markdown
[Документация по теме:]

## Telegram (Telegram боты)
Настройка Telegram-ботов через webhook или long polling...

## Payments (Платежи)
YooMoney webhook принимает POST /webhooks/yoomoney...
```

## Статистика и перезагрузка

### Статистика

API: `GET /admin/wiki-rag/stats`

```json
{
  "stats": {
    "engine": "embeddings+bm25",
    "embedding_engine": "gemini",
    "embedding_sections": 573,
    "sections_indexed": 573,
    "files_indexed": 32,
    "unique_tokens": 2784,
    "avg_doc_length": 36.0,
    "available": true
  }
}
```

Если эмбеддинги не доступны, `"engine": "bm25"`, `"embedding_engine": null`, `"embedding_sections": 0`.

### Перезагрузка индекса

API: `POST /admin/wiki-rag/reload`

Пересканирует все файлы в `wiki-pages/` и перестраивает индекс.

## API эндпоинты

### Управление системой

| Метод | Endpoint | Описание |
|-------|----------|----------|
| GET | `/admin/wiki-rag/stats` | Статистика индекса |
| POST | `/admin/wiki-rag/reload` | Перестроить BM25 индекс + эмбеддинги |
| POST | `/admin/wiki-rag/search` | Поиск по запросу (embeddings → BM25) |
| POST | `/admin/wiki-rag/retrieve` | Получить контекст для промпта |
| POST | `/admin/wiki-rag/reindex-embeddings` | Пересоздать все эмбеддинги с нуля |

### Управление документами

| Метод | Endpoint | Описание |
|-------|----------|----------|
| GET | `/admin/wiki-rag/documents` | Список всех документов |
| POST | `/admin/wiki-rag/documents/upload` | Загрузить `.md` или `.txt` |
| GET | `/admin/wiki-rag/documents/{id}` | Просмотр документа |
| PUT | `/admin/wiki-rag/documents/{id}` | Редактировать документ |
| DELETE | `/admin/wiki-rag/documents/{id}` | Удалить документ |

## RBAC

- **Admin** — полный доступ (загрузка, редактирование, удаление)
- **User/Web** — загрузка, редактирование и удаление своих документов
- **Guest** — только чтение и поиск

## Технические детали

### Токенизация

- **Unicode-aware** — корректно обрабатывает кириллицу
- **Case-insensitive** — приведение к нижнему регистру
- **Стемминг** — Snowball stemmer (русский + английский)
- **Разделители** — пробелы и знаки пунктуации

### BM25 формула

```
BM25(q, d) = Σ IDF(t) × TF_norm(t, d)

IDF(t) = log((N - df(t) + 0.5) / (df(t) + 0.5) + 1)
    N = всего секций
    df(t) = в скольких секциях встречается стем t

TF_norm(t, d) = (tf × (k1 + 1)) / (tf + k1 × (1 - b + b × |d| / avg_dl))
    tf = частота стема t в секции d
    k1 = 1.5 (насыщение TF)
    b = 0.75 (нормализация по длине)
    |d| = длина секции в токенах
    avg_dl = средняя длина секции
```

### Вес заголовков

Токены из `title` секции добавляются в индекс **четырежды** (4x boost), повышая ранжирование по заголовкам.

### Производительность

- **Индексация** — ~1000 секций/сек
- **Поиск** — <10ms для запроса из 5-10 токенов
- **Память** — ~50KB на 1000 секций + стеммер ~100KB

## Интеграция с LLM

Когда включена функция Wiki RAG:

```
1. Пользователь: "Как настроить webhook для Telegram?"
2. Wiki RAG → retrieve("telegram webhook", max_chars=2500)
3. Системный промпт LLM:
   ---
   [Документация по теме:]
   <найденные секции>
   ---
   <стандартный system_prompt>
4. LLM отвечает с учётом документации
```

## Примеры использования

### Документация продукта

Загрузите всю техническую документацию в `wiki-pages/` → ИИ-секретарь будет отвечать на вопросы клиентов, ссылаясь на актуальную документацию.

### База знаний компании

Загрузите регламенты, инструкции, FAQ → боты в Telegram и виджеты на сайте смогут давать точные ответы.

### Обучение персонала

Новые сотрудники задают вопросы ИИ-ассистенту, который ищет информацию в корпоративной wiki.

---

← [[FAQ]] | [[Personas]] →
