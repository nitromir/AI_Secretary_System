#!/usr/bin/env python3
"""
Fine-tune Manager - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –¥–ª—è AI Secretary System.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è.
"""

import ast
import asyncio
import json
import logging
import os
import re
import shutil
import subprocess
import threading
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import AsyncGenerator, Dict, List, Optional, Tuple


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class TrainingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è LoRA"""

    # Model
    base_model: str = "Qwen/Qwen2.5-7B-Instruct"

    # LoRA params
    lora_rank: int = 8
    lora_alpha: int = 16
    lora_dropout: float = 0.05

    # Training params
    batch_size: int = 1
    gradient_accumulation_steps: int = 64
    learning_rate: float = 2e-4
    num_epochs: int = 1
    warmup_ratio: float = 0.03
    weight_decay: float = 0.01
    max_seq_length: int = 768

    # Output
    output_dir: str = "qwen2.5-7b-lydia-lora-new"

    # Advanced
    gradient_checkpointing: bool = True
    fp16: bool = True
    logging_steps: int = 1
    save_steps: int = 100


@dataclass
class AdapterInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ LoRA –∞–¥–∞–ø—Ç–µ—Ä–µ"""

    name: str
    path: str
    size_mb: float
    modified: str
    active: bool = False
    config: Optional[dict] = None


@dataclass
class TrainingStatus:
    """–°—Ç–∞—Ç—É—Å —Ç–µ–∫—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""

    is_running: bool = False
    current_step: int = 0
    total_steps: int = 0
    current_epoch: int = 0
    total_epochs: int = 0
    loss: float = 0.0
    learning_rate: float = 0.0
    elapsed_seconds: float = 0.0
    eta_seconds: float = 0.0
    error: Optional[str] = None


@dataclass
class DatasetStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""

    total_sessions: int = 0
    total_messages: int = 0
    total_tokens: int = 0
    avg_tokens_per_message: float = 0.0
    file_path: Optional[str] = None
    file_size_mb: float = 0.0
    modified: Optional[str] = None


@dataclass
class ProcessingStatus:
    """–°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""

    is_running: bool = False
    stage: str = ""  # "parsing", "transcribing", "building"
    current: int = 0
    total: int = 0
    voice_transcribed: int = 0
    voice_total: int = 0
    error: Optional[str] = None


@dataclass
class DatasetConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""

    owner_name: str = "–ê—Ä—Ç–µ–º –Æ—Ä—å–µ–≤–∏—á"
    transcribe_voice: bool = False
    min_dialog_messages: int = 2
    max_message_length: int = 2000
    max_dialog_length: int = 20
    include_groups: bool = False
    output_name: str = "dataset"


class FinetuneManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–æ–æ–±—É—á–µ–Ω–∏—è LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤.

    –§—É–Ω–∫—Ü–∏–∏:
    - –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (Telegram export)
    - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    - –ó–∞–ø—É—Å–∫/–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è
    - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (SSE)
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–∞–º–∏ (–∞–∫—Ç–∏–≤–∞—Ü–∏—è, —É–¥–∞–ª–µ–Ω–∏–µ)
    """

    # –ü—É—Ç–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ª–æ–∫–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏)
    EXTERNAL_DATA_DIR = Path(os.path.expanduser("~/qwen-finetune"))  # –í–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ
    VENV_PATH = EXTERNAL_DATA_DIR / "train_venv"  # venv –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

    # –°–∫—Ä–∏–ø—Ç—ã (–≤ finetune/)
    PREPARE_SCRIPT = "prepare_dataset.py"
    TRAIN_SCRIPT = "train.py"
    MERGE_SCRIPT = "merge_lora.py"
    QUANTIZE_SCRIPT = "quantize_awq.py"

    def __init__(self, base_dir: Optional[Path] = None):
        self.base_dir = base_dir or Path(__file__).parent

        # –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏ (–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏)
        self.finetune_dir = self.base_dir / "finetune"
        self.datasets_dir = self.finetune_dir / "datasets"
        self.adapters_dir = self.finetune_dir / "adapters"

        # –í–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        self.external_data_dir = self.EXTERNAL_DATA_DIR

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
        self.training_process: Optional[subprocess.Popen] = None
        self.training_config: Optional[TrainingConfig] = None
        self.training_status = TrainingStatus()
        self.training_log: List[str] = []
        self.training_start_time: Optional[datetime] = None
        self._training_lock = threading.Lock()

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
        self.processing_status = ProcessingStatus()
        self.dataset_config = DatasetConfig()
        self._processing_lock = threading.Lock()
        self._stt_service = None  # Lazy load

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        self.datasets_dir.mkdir(parents=True, exist_ok=True)
        self.adapters_dir.mkdir(parents=True, exist_ok=True)

        # –¢–µ–∫—É—â–∏–π –∞–∫—Ç–∏–≤–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä
        self.active_adapter: Optional[str] = None
        self._load_active_adapter()

        logger.info("üéì FinetuneManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   üìÅ Finetune dir: {self.finetune_dir}")
        logger.info(f"   üìä Datasets: {self.datasets_dir}")
        logger.info(f"   üîß Adapters: {self.adapters_dir}")

    def _load_active_adapter(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫—Ç–∏–≤–Ω–æ–º –∞–¥–∞–ø—Ç–µ—Ä–µ"""
        active_file = self.adapters_dir / ".active"
        if active_file.exists():
            self.active_adapter = active_file.read_text().strip()

    def _save_active_adapter(self, adapter_name: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä"""
        active_file = self.adapters_dir / ".active"
        active_file.write_text(adapter_name)
        self.active_adapter = adapter_name

    def _run_script(
        self, script_name: str, args: List[str] = None, capture_output: bool = True
    ) -> dict:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Python —Å–∫—Ä–∏–ø—Ç –≤ venv finetune"""
        script_path = self.finetune_dir / script_name
        if not script_path.exists():
            return {"status": "error", "message": f"–°–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {script_name}"}

        python_path = self.VENV_PATH / "bin" / "python"
        if not python_path.exists():
            # Fallback –Ω–∞ —Å–∏—Å—Ç–µ–º–Ω—ã–π python
            python_path = "python3"
            logger.warning(f"‚ö†Ô∏è venv –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.VENV_PATH}, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π python")

        cmd = [str(python_path), str(script_path)]
        if args:
            cmd.extend(args)

        try:
            result = subprocess.run(
                cmd,
                cwd=str(self.finetune_dir),
                capture_output=capture_output,
                text=True,
                timeout=600,  # 10 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
            )

            if result.returncode == 0:
                return {"status": "ok", "stdout": result.stdout, "stderr": result.stderr}
            else:
                return {
                    "status": "error",
                    "message": result.stderr or result.stdout,
                    "returncode": result.returncode,
                }
        except subprocess.TimeoutExpired:
            return {"status": "error", "message": "–¢–∞–π–º–∞—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞"}
        except Exception as e:
            return {"status": "error", "message": str(e)}

    # ============== Dataset Operations ==============

    async def upload_dataset(self, content: bytes, filename: str) -> dict:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (Telegram export JSON).
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            if filename.endswith(".json"):
                dest_path = self.datasets_dir / "result.json"
            else:
                dest_path = self.datasets_dir / filename

            dest_path.write_bytes(content)
            file_size = len(content) / (1024 * 1024)

            logger.info(f"üì• –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {dest_path} ({file_size:.2f} MB)")

            return {
                "status": "ok",
                "message": f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {dest_path.name}",
                "path": str(dest_path),
                "size_mb": round(file_size, 2),
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
            return {"status": "error", "message": str(e)}

    def _get_stt_service(self):
        """Lazy load STT service for voice transcription"""
        if self._stt_service is None:
            try:
                from stt_service import STTService

                self._stt_service = STTService(
                    model_size="base", use_faster_whisper=True, device="cpu"
                )
                logger.info("‚úÖ STT —Å–µ—Ä–≤–∏—Å –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è STT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                self._stt_service = False  # Mark as unavailable
        return self._stt_service if self._stt_service else None

    def _extract_text(self, text_field) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –ø–æ–ª—è (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ —Å–ø–∏—Å–∫–æ–º)"""
        if isinstance(text_field, str):
            return text_field.strip()
        if isinstance(text_field, list):
            parts = []
            for item in text_field:
                if isinstance(item, str):
                    parts.append(item)
                elif isinstance(item, dict):
                    parts.append(item.get("text", ""))
            return "".join(parts).strip()
        return ""

    def _transcribe_voice(self, voice_path: Path, telegram_export_dir: Path) -> Optional[str]:
        """–†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        stt = self._get_stt_service()
        if not stt:
            return None

        # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∞ Telegram
        full_path = telegram_export_dir / voice_path
        if not full_path.exists():
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ datasets_dir
            full_path = self.datasets_dir / voice_path
        if not full_path.exists():
            logger.warning(f"–ì–æ–ª–æ—Å–æ–≤–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {voice_path}")
            return None

        try:
            result = stt.transcribe(str(full_path), language="ru")
            return result.get("text", "").strip()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ {voice_path}: {e}")
            return None

    def get_dataset_config(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return asdict(self.dataset_config)

    def set_dataset_config(self, **kwargs) -> dict:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        for key, value in kwargs.items():
            if hasattr(self.dataset_config, key):
                setattr(self.dataset_config, key, value)
        return {"status": "ok", "config": asdict(self.dataset_config)}

    def get_processing_status(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        with self._processing_lock:
            return asdict(self.processing_status)

    async def process_dataset(self, config: Optional[dict] = None) -> dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç Telegram export –∏ —Å–æ–∑–¥–∞–µ—Ç JSONL –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
        """
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞
        if config:
            self.set_dataset_config(**config)

        cfg = self.dataset_config

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ result.json
        input_file = self.datasets_dir / "result.json"
        if not input_file.exists():
            return {
                "status": "error",
                "message": "–§–∞–π–ª result.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–≥—Ä—É–∑–∏—Ç–µ Telegram export.",
            }

        with self._processing_lock:
            if self.processing_status.is_running:
                return {"status": "error", "message": "–û–±—Ä–∞–±–æ—Ç–∫–∞ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–∞"}
            self.processing_status = ProcessingStatus(is_running=True, stage="parsing")

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º Telegram export
            logger.info(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ {input_file}...")
            with open(input_file, encoding="utf-8") as f:
                data = json.load(f)

            chat_list = data.get("chats", {}).get("list", [])
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —á–∞—Ç–æ–≤: {len(chat_list)}")

            with self._processing_lock:
                self.processing_status.total = len(chat_list)

            all_dialogs = []
            voice_messages = []  # –î–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
            stats = {
                "total_chats": len(chat_list),
                "processed_chats": 0,
                "skipped_chats": 0,
                "voice_messages": 0,
            }

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞–º–∏
            telegram_export_dir = input_file.parent

            for idx, chat in enumerate(chat_list):
                with self._processing_lock:
                    self.processing_status.current = idx + 1

                chat_type = chat.get("type", "")

                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É —á–∞—Ç–∞
                if chat_type == "personal_chat":
                    pass  # –í—Å–µ–≥–¥–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                elif chat_type in [
                    "private_group",
                    "public_group",
                    "private_supergroup",
                    "public_supergroup",
                ]:
                    if not cfg.include_groups:
                        stats["skipped_chats"] += 1
                        continue
                else:
                    stats["skipped_chats"] += 1
                    continue

                messages = chat.get("messages", [])
                current_dialog = []
                prev_role = None

                for msg in messages:
                    if msg.get("type") != "message":
                        continue

                    sender = msg.get("from", "")
                    text = self._extract_text(msg.get("text", ""))

                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
                    media_type = msg.get("media_type")
                    if media_type == "voice_message" and cfg.transcribe_voice:
                        voice_file = msg.get("file")
                        if voice_file:
                            stats["voice_messages"] += 1
                            voice_messages.append(
                                {
                                    "file": voice_file,
                                    "sender": sender,
                                    "dialog_idx": len(all_dialogs),
                                    "msg_idx": len(current_dialog),
                                    "export_dir": telegram_export_dir,
                                }
                            )
                            # Placeholder - –±—É–¥–µ—Ç –∑–∞–º–µ–Ω–µ–Ω –ø–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
                            text = f"[VOICE:{voice_file}]"

                    if not text or len(text) < 1:
                        continue

                    if len(text) > cfg.max_message_length:
                        text = text[: cfg.max_message_length] + "..."

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª—å
                    role = "assistant" if sender == cfg.owner_name else "user"

                    # –°–∫–ª–µ–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    if role == prev_role and current_dialog:
                        current_dialog[-1]["value"] += "\n" + text
                    else:
                        current_dialog.append({"from": role, "value": text})

                    prev_role = role

                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏
                for i in range(0, len(current_dialog), cfg.max_dialog_length):
                    chunk = current_dialog[i : i + cfg.max_dialog_length]

                    # –î–∏–∞–ª–æ–≥ –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å user –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è assistant
                    while chunk and chunk[0]["from"] == "assistant":
                        chunk = chunk[1:]
                    while chunk and chunk[-1]["from"] == "user":
                        chunk = chunk[:-1]

                    if len(chunk) >= cfg.min_dialog_messages:
                        has_user = any(m["from"] == "user" for m in chunk)
                        has_assistant = any(m["from"] == "assistant" for m in chunk)
                        if has_user and has_assistant:
                            all_dialogs.append({"messages": chunk})

                if current_dialog:
                    stats["processed_chats"] += 1
                else:
                    stats["skipped_chats"] += 1

            # –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            if voice_messages and cfg.transcribe_voice:
                with self._processing_lock:
                    self.processing_status.stage = "transcribing"
                    self.processing_status.voice_total = len(voice_messages)
                    self.processing_status.voice_transcribed = 0

                logger.info(f"üé§ –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ {len(voice_messages)} –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")

                for vm in voice_messages:
                    transcribed = self._transcribe_voice(Path(vm["file"]), vm["export_dir"])
                    if transcribed:
                        # –ù–∞—Ö–æ–¥–∏–º –∏ –∑–∞–º–µ–Ω—è–µ–º placeholder
                        # –≠—Ç–æ —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã
                        for dialog in all_dialogs:
                            for msg in dialog["messages"]:
                                placeholder = f"[VOICE:{vm['file']}]"
                                if placeholder in msg["value"]:
                                    msg["value"] = msg["value"].replace(placeholder, transcribed)

                    with self._processing_lock:
                        self.processing_status.voice_transcribed += 1

            # –£–¥–∞–ª—è–µ–º –Ω–µ—Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
            for dialog in all_dialogs:
                dialog["messages"] = [
                    m for m in dialog["messages"] if not m["value"].startswith("[VOICE:")
                ]
            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –¥–∏–∞–ª–æ–≥–∏
            all_dialogs = [d for d in all_dialogs if len(d["messages"]) >= cfg.min_dialog_messages]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with self._processing_lock:
                self.processing_status.stage = "building"

            output_file = self.datasets_dir / f"{cfg.output_name}_dataset.jsonl"
            with open(output_file, "w", encoding="utf-8") as f:
                for dialog in all_dialogs:
                    f.write(json.dumps(dialog, ensure_ascii=False) + "\n")

            total_messages = sum(len(d["messages"]) for d in all_dialogs)
            logger.info(
                f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω: {len(all_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤, {total_messages} —Å–æ–æ–±—â–µ–Ω–∏–π"
            )

            return {
                "status": "ok",
                "message": f"–î–∞—Ç–∞—Å–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(all_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤",
                "output_file": str(output_file),
                "stats": {
                    **stats,
                    "total_dialogs": len(all_dialogs),
                    "total_messages": total_messages,
                },
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return {"status": "error", "message": str(e)}

        finally:
            with self._processing_lock:
                self.processing_status.is_running = False
                self.processing_status.stage = ""

    def get_dataset_stats(self, dataset_file: Optional[str] = None) -> DatasetStats:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞.
        –ï—Å–ª–∏ dataset_file –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π .jsonl
        """
        stats = DatasetStats()

        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞
        if dataset_file:
            train_file = Path(dataset_file)
        else:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π .jsonl —Ñ–∞–π–ª
            jsonl_files = list(self.datasets_dir.glob("*.jsonl"))
            if not jsonl_files:
                return stats
            train_file = max(jsonl_files, key=lambda f: f.stat().st_mtime)

        if not train_file.exists():
            return stats

        try:
            stat = train_file.stat()
            stats.file_path = str(train_file)
            stats.file_size_mb = round(stat.st_size / (1024 * 1024), 2)
            stats.modified = datetime.fromtimestamp(stat.st_mtime).isoformat()

            # –ü–∞—Ä—Å–∏–º JSONL
            with open(train_file, encoding="utf-8") as f:
                sessions = [json.loads(line) for line in f if line.strip()]

            stats.total_sessions = len(sessions)

            total_messages = 0
            total_chars = 0

            for session in sessions:
                messages = session.get("conversations", session.get("messages", []))
                total_messages += len(messages)
                for msg in messages:
                    content = msg.get("value", msg.get("content", ""))
                    total_chars += len(content)

            stats.total_messages = total_messages
            # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ~ 3 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
            stats.total_tokens = total_chars // 3
            stats.avg_tokens_per_message = round(stats.total_tokens / max(1, total_messages), 1)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")

        return stats

    def list_datasets(self) -> List[dict]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.
        """
        datasets = []

        for f in self.datasets_dir.iterdir():
            if f.suffix == ".jsonl" and f.is_file():
                stat = f.stat()
                datasets.append(
                    {
                        "name": f.name,
                        "path": str(f),
                        "size_mb": round(stat.st_size / (1024 * 1024), 2),
                        "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    }
                )
            elif f.suffix == ".json" and f.name == "result.json":
                stat = f.stat()
                datasets.append(
                    {
                        "name": f.name,
                        "path": str(f),
                        "size_mb": round(stat.st_size / (1024 * 1024), 2),
                        "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": "telegram_export",
                    }
                )

        return sorted(datasets, key=lambda x: x["modified"], reverse=True)

    async def augment_dataset(self) -> dict:
        """
        –ê—É–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç (—É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ).
        –ü–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ.
        """
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        return {
            "status": "ok",
            "message": "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã.",
            "stats": asdict(self.get_dataset_stats()),
        }

    # ============== Project Dataset Generation ==============

    async def generate_project_dataset(
        self,
        include_tz: bool = True,
        include_faq: bool = True,
        include_docs: bool = True,
        include_escalation: bool = True,
        include_code: bool = True,
        output_name: str = "project_dataset",
    ) -> dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        –∫–∞–∫ —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ –ø—Ä–æ–¥–∞–≤—Ü–∞ —É—Å–ª—É–≥.

        –ò—Å—Ç–æ—á–Ω–∏–∫–∏:
        - docs/tz/tz_tg_bot.md ‚Äî –ø—Ä–æ–¥–∞–∂–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏, —Ü–µ–Ω—ã, –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
        - FAQ –∏–∑ –ë–î ‚Äî —Ç–∏–ø–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã-–æ—Ç–≤–µ—Ç—ã
        - CLAUDE.md + docs/ ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
        - –®–∞–±–ª–æ–Ω—ã —ç—Å–∫–∞–ª–∞—Ü–∏–∏ ‚Äî –ø—Ä–∏–º–µ—Ä—ã –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–∞ —Å—Ç–∞—Ä—à–∏–π —É—Ä–æ–≤–µ–Ω—å
        - Python –∫–æ–¥ ‚Äî endpoints, models, docstrings (NEW)
        - Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ‚Äî README, wiki-pages (NEW)
        """
        all_dialogs: List[dict] = []
        sources_stats: Dict[str, int] = {}

        try:
            if include_tz:
                tz_dialogs = self._generate_from_tz()
                all_dialogs.extend(tz_dialogs)
                sources_stats["tz_sales"] = len(tz_dialogs)

            if include_faq:
                faq_dialogs = await self._generate_from_faq()
                all_dialogs.extend(faq_dialogs)
                sources_stats["faq"] = len(faq_dialogs)

            if include_docs:
                docs_dialogs = self._generate_from_docs()
                all_dialogs.extend(docs_dialogs)
                sources_stats["docs"] = len(docs_dialogs)

            if include_escalation:
                escalation_dialogs = self._generate_escalation_examples()
                all_dialogs.extend(escalation_dialogs)
                sources_stats["escalation"] = len(escalation_dialogs)

            if include_code:
                # –ü–∞—Ä—Å–∏–Ω–≥ Python –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞
                code_dialogs = self._generate_from_python_code()
                all_dialogs.extend(code_dialogs)
                sources_stats["python_code"] = len(code_dialogs)

                # –ü–∞—Ä—Å–∏–Ω–≥ Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
                md_dialogs = self._generate_from_markdown_docs()
                all_dialogs.extend(md_dialogs)
                sources_stats["markdown_docs"] = len(md_dialogs)

            if not all_dialogs:
                return {
                    "status": "error",
                    "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.",
                }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            output_file = self.datasets_dir / f"{output_name}.jsonl"
            with open(output_file, "w", encoding="utf-8") as f:
                for dialog in all_dialogs:
                    f.write(json.dumps(dialog, ensure_ascii=False) + "\n")

            total_messages = sum(len(d["messages"]) for d in all_dialogs)

            logger.info(
                f"‚úÖ –ü—Ä–æ–µ–∫—Ç–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω: {len(all_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤, "
                f"{total_messages} —Å–æ–æ–±—â–µ–Ω–∏–π ‚Üí {output_file}"
            )

            return {
                "status": "ok",
                "message": f"–î–∞—Ç–∞—Å–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(all_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤",
                "output_file": str(output_file),
                "stats": {
                    "total_dialogs": len(all_dialogs),
                    "total_messages": total_messages,
                    "sources": sources_stats,
                },
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
            return {"status": "error", "message": str(e)}

    def _make_dialog(self, pairs: List[tuple]) -> dict:
        """–°–æ–∑–¥–∞—ë—Ç –¥–∏–∞–ª–æ–≥ –∏–∑ —Å–ø–∏—Å–∫–∞ –ø–∞—Ä (user, assistant)."""
        messages = []
        for user_msg, assistant_msg in pairs:
            messages.append({"from": "user", "value": user_msg})
            messages.append({"from": "assistant", "value": assistant_msg})
        return {"messages": messages}

    def _generate_from_tz(self) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∏–∞–ª–æ–≥–∏ –∏–∑ –¢–ó –ø—Ä–æ–¥–∞–∂–Ω–æ–≥–æ –±–æ—Ç–∞ (docs/tz/tz_tg_bot.md)."""
        dialogs = []
        tz_file = self.base_dir / "docs" / "tz" / "tz_tg_bot.md"
        if not tz_file.exists():
            logger.warning(f"‚ö†Ô∏è –¢–ó –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {tz_file}")
            return dialogs

        # --- –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ß—Ç–æ —Ç–∞–∫–æ–µ AI Secretary?",
                        "AI Secretary ‚Äî —ç—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ –≤–∞—à–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ. "
                        "–û–Ω –≥–æ–≤–æ—Ä–∏—Ç –≤–∞—à–∏–º –≥–æ–ª–æ—Å–æ–º –±–ª–∞–≥–æ–¥–∞—Ä—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—é, —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, "
                        "–±–µ–∑ –∞–±–æ–Ω–µ–Ω—Ç—Å–∫–æ–π –ø–ª–∞—Ç—ã. –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ—Å—Ç–∞—é—Ç—Å—è —É –≤–∞—Å.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫–∏–µ —É –≤–∞—Å –µ—Å—Ç—å —Ç–∞—Ä–∏—Ñ—ã?",
                        "–ï—Å—Ç—å —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞:\n\n"
                        "1. –ë–µ—Å–ø–ª–∞—Ç–Ω–æ ‚Äî —Å–∫–∞—á–∏–≤–∞–µ—Ç–µ —Å GitHub –∏ —Å—Ç–∞–≤–∏—Ç–µ —Å–∞–º–∏\n"
                        "2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ ¬´–ø–æ–¥ –∫–ª—é—á¬ª ‚Äî 5,000‚ÇΩ —Ä–∞–∑–æ–≤–æ. –Ø –ø–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ –≤–∞—à–µ–º—É —Å–µ—Ä–≤–µ—Ä—É "
                        "–∏ –≤—Å—ë –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é –∑–∞ 30 –º–∏–Ω—É—Ç\n"
                        "3. –ö–∞—Å—Ç–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ ‚Äî –æ—Ç 50,000‚ÇΩ. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CRM, —Ç–µ–ª–µ—Ñ–æ–Ω–∏–µ–π, "
                        "–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n\n"
                        "–ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤–∞–º –±–ª–∏–∂–µ?",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∞?",
                        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ ¬´–ø–æ–¥ –∫–ª—é—á¬ª —Å—Ç–æ–∏—Ç 5,000‚ÇΩ ‚Äî —ç—Ç–æ —Ä–∞–∑–æ–≤—ã–π –ø–ª–∞—Ç—ë–∂. "
                        "–Ø –ø–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ –≤–∞—à–µ–º—É —Å–µ—Ä–≤–µ—Ä—É –ø–æ SSH, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Å–∏—Å—Ç–µ–º—É, "
                        "–æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—é –ø–æ–¥ –≤–∞—à GPU –∏ –ø—Ä–æ–≤–µ—Ä—è—é —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å. "
                        "–í–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–Ω–∏–º–∞–µ—Ç –æ–∫–æ–ª–æ 30 –º–∏–Ω—É—Ç. "
                        "–ì–∞—Ä–∞–Ω—Ç–∏—è: –µ—Å–ª–∏ –Ω–µ –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –≤–µ—Ä–Ω—É –¥–µ–Ω—å–≥–∏.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ó–∞—á–µ–º –º–Ω–µ —ç—Ç–æ, –µ—Å–ª–∏ –µ—Å—Ç—å ChatGPT?",
                        "–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ö–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è:\n\n"
                        "‚Ä¢ –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å ‚Äî –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ —É—Ö–æ–¥—è—Ç –Ω–∞ —á—É–∂–∏–µ —Å–µ—Ä–≤–µ—Ä—ã (GDPR, 152-–§–ó)\n"
                        "‚Ä¢ –ù–µ—Ç –∞–±–æ–Ω–µ–Ω—Ç–∫–∏ ‚Äî –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞—Å—Ç—Ä–æ–∏–ª –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ\n"
                        "‚Ä¢ –í–∞—à –≥–æ–ª–æ—Å ‚Äî AI –≥–æ–≤–æ—Ä–∏—Ç –≤–∞—à–∏–º –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º\n"
                        "‚Ä¢ –†–∞–±–æ—Ç–∞–µ—Ç –æ—Ñ–ª–∞–π–Ω ‚Äî –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞\n"
                        "‚Ä¢ –ü–æ–ª–Ω–∞—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è ‚Äî –æ–±—É—á–∞–µ—Ç–µ –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n\n"
                        "–¢–∏–ø–∏—á–Ω—ã–π SaaS-–±–æ—Ç —Å—Ç–æ–∏—Ç 15,000‚ÇΩ/–º–µ—Å. –ó–∞ 3 –≥–æ–¥–∞ —ç—Ç–æ 540,000‚ÇΩ. "
                        "AI Secretary –æ–∫—É–ø–∞–µ—Ç—Å—è –∑–∞ 10 –¥–Ω–µ–π.",
                    ),
                ]
            )
        )

        # --- –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∂–µ–ª–µ–∑—É ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫–æ–π GPU –Ω—É–∂–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã?",
                        "–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω—É–∂–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:\n\n"
                        "‚Ä¢ GTX 1660 (6 –ì–ë) ‚Äî Qwen-3B, –±–∞–∑–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ ‚≠ê‚≠ê\n"
                        "‚Ä¢ RTX 3060 (12 –ì–ë) ‚Äî Qwen-7B, —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ ‚≠ê‚≠ê‚≠ê\n"
                        "‚Ä¢ RTX 3090 (24 –ì–ë) ‚Äî Qwen-14B, –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ ‚≠ê‚≠ê‚≠ê‚≠ê\n"
                        "‚Ä¢ RTX 4090 (24 –ì–ë) ‚Äî Qwen-32B, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n\n"
                        "–ù–µ—Ç GPU? –ï—Å—Ç—å CPU-—Ä–µ–∂–∏–º —Å –æ–±–ª–∞—á–Ω—ã–º LLM (Gemini API) ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω–æ.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–£ –º–µ–Ω—è –Ω–µ—Ç GPU, –º–æ–≥—É –ª–∏ —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É?",
                        "–î–∞! –ï—Å—Ç—å —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞:\n\n"
                        "1. CPU + –æ–±–ª–∞—á–Ω—ã–π LLM (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)\n"
                        "   –ì–æ–ª–æ—Å: Piper TTS (–±—ã—Å—Ç—Ä—ã–π, –Ω–∞ CPU)\n"
                        "   –ú–æ–∑–≥–∏: Gemini API (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∏—Ä)\n"
                        "   –ö–∞—á–µ—Å—Ç–≤–æ: —Ö–æ—Ä–æ—à–µ–µ ‚≠ê‚≠ê‚≠ê\n\n"
                        "2. –ê—Ä–µ–Ω–¥–∞ VPS —Å GPU ‚Äî –æ—Ç 3,000‚ÇΩ/–º–µ—Å –∑–∞ RTX 3060\n\n"
                        "3. –°–≤–æ–π –º–∏–Ω–∏-—Å–µ—Ä–≤–µ—Ä ‚Äî RTX 3060 –±/—É ~25,000‚ÇΩ, "
                        "–æ–∫—É–ø–∞–µ—Ç—Å—è –∑–∞ 8 –º–µ—Å—è—Ü–µ–≤ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å VPS\n\n"
                        "–ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤–∞–º –±–ª–∏–∂–µ?",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è?",
                        "–ú–∏–Ω–∏–º—É–º:\n"
                        "‚Ä¢ –û–°: Ubuntu 20.04+ –∏–ª–∏ Debian 11+\n"
                        "‚Ä¢ RAM: 8 –ì–ë (16 –ì–ë —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)\n"
                        "‚Ä¢ –î–∏—Å–∫: 20 –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞\n"
                        "‚Ä¢ Docker —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n\n"
                        "–î–ª—è GPU-—Ä–µ–∂–∏–º–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:\n"
                        "‚Ä¢ NVIDIA GPU —Å CUDA Compute Capability ‚â• 7.0\n"
                        "‚Ä¢ NVIDIA Driver ‚â• 525\n"
                        "‚Ä¢ nvidia-container-toolkit\n\n"
                        "–î–ª—è CPU-—Ä–µ–∂–∏–º–∞ GPU –Ω–µ –Ω—É–∂–µ–Ω ‚Äî –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è "
                        "–æ–±–ª–∞—á–Ω—ã–π LLM –∏ –ª—ë–≥–∫–∏–π TTS.",
                    ),
                ]
            )
        )

        # --- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å AI Secretary?",
                        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è ‚Äî 5 –º–∏–Ω—É—Ç:\n\n"
                        "```\n"
                        "git clone https://github.com/ShaerWare/AI_Secretary_System\n"
                        "cd AI_Secretary_System\n"
                        "cp .env.example .env\n"
                        "docker compose up -d\n"
                        "```\n\n"
                        "–ê–¥–º–∏–Ω–∫–∞: http://localhost:8002/admin\n"
                        "–õ–æ–≥–∏–Ω: admin / admin\n\n"
                        "–ï—Å–ª–∏ –∑–∞—Å—Ç—Ä—è–Ω–µ—Ç–µ ‚Äî –ø–∏—à–∏—Ç–µ, –ø–æ–º–æ–≥—É! "
                        "–ò–ª–∏ –º–æ–≥—É —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞ –≤–∞—Å –∑–∞ 5,000‚ÇΩ.",
                    ),
                ]
            )
        )

        # --- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –µ—Å—Ç—å —É —Å–∏—Å—Ç–µ–º—ã?",
                        "AI Secretary —É–º–µ–µ—Ç:\n\n"
                        "üó£Ô∏è –ì–æ–ª–æ—Å:\n"
                        "‚Ä¢ –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ (XTTS v2) ‚Äî –≥–æ–≤–æ—Ä–∏—Ç –≤–∞—à–∏–º –≥–æ–ª–æ—Å–æ–º\n"
                        "‚Ä¢ –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–∞ (Piper) ‚Äî –±—ã—Å—Ç—Ä—ã–π CPU-—Ä–µ–∂–∏–º\n\n"
                        "üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç:\n"
                        "‚Ä¢ –õ–æ–∫–∞–ª—å–Ω—ã–π LLM (vLLM + Qwen/Llama/DeepSeek)\n"
                        "‚Ä¢ –û–±–ª–∞—á–Ω—ã–µ LLM (Gemini, OpenAI, Claude, DeepSeek)\n"
                        "‚Ä¢ FAQ-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n\n"
                        "üì± –ö–∞–Ω–∞–ª—ã:\n"
                        "‚Ä¢ Telegram-–±–æ—Ç (–º—É–ª—å—Ç–∏-–∏–Ω—Å—Ç–∞–Ω—Å—ã)\n"
                        "‚Ä¢ –í–∏–¥–∂–µ—Ç –¥–ª—è —Å–∞–π—Ç–∞\n"
                        "‚Ä¢ GSM-—Ç–µ–ª–µ—Ñ–æ–Ω–∏—è (SIM7600E-H)\n"
                        "‚Ä¢ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API\n\n"
                        "‚öôÔ∏è –ê–¥–º–∏–Ω–∫–∞: 14 –≤–∫–ª–∞–¥–æ–∫, PWA, —Ç–µ–º—ã, i18n (ru/en)",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ú–æ–∂–Ω–æ –ª–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å CRM?",
                        "–î–∞, –≤ —Ä–∞–º–∫–∞—Ö –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º:\n\n"
                        "‚Ä¢ Bitrix24\n"
                        "‚Ä¢ amoCRM\n"
                        "‚Ä¢ 1–°\n"
                        "‚Ä¢ –¢–µ–ª–µ—Ñ–æ–Ω–∏—è (SIP/GSM)\n"
                        "‚Ä¢ –õ—é–±–∞—è —Å–∏—Å—Ç–µ–º–∞ —á–µ—Ä–µ–∑ API\n\n"
                        "–°—Ç–æ–∏–º–æ—Å—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ ‚Äî –æ—Ç 20,000‚ÇΩ –∑–∞ –æ–¥–Ω—É —Å–∏—Å—Ç–µ–º—É. "
                        "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–π –∑–∞–¥–∞—á–µ, –∏ —è –ø–æ–¥–≥–æ—Ç–æ–≤–ª—é —Ä–∞—Å—á—ë—Ç.",
                    ),
                ]
            )
        )

        # --- –í–æ–∑—Ä–∞–∂–µ–Ω–∏—è ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–î–æ—Ä–æ–≥–æ, –µ—Å—Ç—å —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–ø—Ä–æ—â–µ?",
                        "–ö–æ–Ω–µ—á–Ω–æ! –ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:\n\n"
                        "1. MVP-–≤–µ—Ä—Å–∏—è (–±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç) ‚Äî 50,000‚ÇΩ\n"
                        "   –ë–∞–∑–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –±–µ–∑ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π, –≤—ã —Å–∞–º–∏ —Å–≤—è–∑—ã–≤–∞–µ—Ç–µ —Å CRM\n\n"
                        "2. –ü–æ—ç—Ç–∞–ø–Ω–æ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ\n"
                        "   –°–Ω–∞—á–∞–ª–∞ –±–∞–∑–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –ø–æ—Ç–æ–º –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏. "
                        "–ü–ª–∞—Ç–∏—Ç–µ –ø–æ —á–∞—Å—Ç—è–º\n\n"
                        "3. Self-hosted —Å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–µ–π ‚Äî 15,000‚ÇΩ\n"
                        "   –°—Ç–∞–≤–∏—Ç–µ —Å–∞–º–∏ —Å GitHub, —è –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É—é –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ\n\n"
                        "–ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω–µ–µ?",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ê —ç—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ? –ì–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –¥–∞–Ω–Ω—ã–µ?",
                        "–≠—Ç–æ –æ–¥–Ω–æ –∏–∑ –≥–ª–∞–≤–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤ AI Secretary ‚Äî "
                        "–≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–∞—à–µ–º —Å–µ—Ä–≤–µ—Ä–µ.\n\n"
                        "‚Ä¢ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å ‚Äî –∑–∞–ø—Ä–æ—Å—ã –Ω–µ —É—Ö–æ–¥—è—Ç –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç\n"
                        "‚Ä¢ SQLite –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ‚Äî –Ω–∞ –≤–∞—à–µ–º –¥–∏—Å–∫–µ\n"
                        "‚Ä¢ –ù–µ—Ç —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ –∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞\n"
                        "‚Ä¢ –ü–æ–ª–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ 152-–§–ó –∏ GDPR\n\n"
                        "–í—ã –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π, –∫—Ç–æ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º.",
                    ),
                ]
            )
        )

        # --- –ö–µ–π—Å—ã –∏ social proof ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–£ –≤–∞—Å –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä—ã –≤–Ω–µ–¥—Ä–µ–Ω–∏—è?",
                        "–î–∞, –≤–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–µ–π—Å–æ–≤:\n\n"
                        "üè¢ –ê–≤—Ç–æ—Å–∞–ª–æ–Ω ‚Äî —Å–Ω–∏–∑–∏–ª–∏ –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –Ω–∞ 70%. "
                        "–ë–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Ç–∏–ø–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∞–ª–∏—á–∏–∏, —Ü–µ–Ω–∞—Ö, –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è—Ö\n\n"
                        "üè• –ö–ª–∏–Ω–∏–∫–∞ ‚Äî –∞–≤—Ç–æ–∑–∞–ø–∏—Å—å 24/7, +40% –∑–∞–ø–∏—Å–µ–π –Ω–∞ –ø—Ä–∏—ë–º. "
                        "–ë–æ—Ç –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤, –Ω–∞–ø–æ–º–∏–Ω–∞–µ—Ç –æ –≤–∏–∑–∏—Ç–∞—Ö\n\n"
                        "üõí E-commerce ‚Äî –±–æ—Ç-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç, +25% –∫–æ–Ω–≤–µ—Ä—Å–∏–∏. "
                        "–ü–æ–º–æ–≥–∞–µ—Ç –≤—ã–±—Ä–∞—Ç—å —Ç–æ–≤–∞—Ä, –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã\n\n"
                        "–•–æ—Ç–∏—Ç–µ –æ–±—Å—É–¥–∏—Ç—å –≤–∞—à –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–ª—É—á–∞–π?",
                    ),
                ]
            )
        )

        # --- –ú—É–ª—å—Ç–∏—Ö–æ–¥–æ–≤—ã–µ –¥–∏–∞–ª–æ–≥–∏ ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ü—Ä–∏–≤–µ—Ç! –•–æ—á—É –ø–æ—Å—Ç–∞–≤–∏—Ç—å AI-—Å–µ–∫—Ä–µ—Ç–∞—Ä—è –¥–ª—è –±–∏–∑–Ω–µ—Å–∞",
                        "–û—Ç–ª–∏—á–Ω–æ! –î–∞–≤–∞–π—Ç–µ –ø–æ–¥–±–µ—Ä—ë–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç. "
                        "–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –ø–∞—Ä—É –≤–æ–ø—Ä–æ—Å–æ–≤:\n\n"
                        "–ö–∞–∫ –≤—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ—Å—å –∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Å—Ç–æ—Ä–æ–Ω–µ?\n"
                        "1. –õ—é–±–ª—é —Å–∞–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö\n"
                        "2. –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é –≥–æ—Ç–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ\n"
                        "3. –£ –º–µ–Ω—è –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–∞, –Ω—É–∂–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è",
                    ),
                    (
                        "2, –º–Ω–µ –Ω—É–∂–Ω–æ –≥–æ—Ç–æ–≤–æ–µ",
                        "–ü–æ–Ω—è–ª! –¢–æ–≥–¥–∞ –≤–∞—Ä–∏–∞–Ω—Ç ¬´–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–¥ –∫–ª—é—á¬ª –∑–∞ 5,000‚ÇΩ ‚Äî —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ.\n\n"
                        "–ï—Å—Ç—å –ª–∏ —É –≤–∞—Å —Å–µ—Ä–≤–µ—Ä –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏?\n"
                        "1. –î–∞, –µ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä —Å GPU\n"
                        "2. –ï—Å—Ç—å —Å–µ—Ä–≤–µ—Ä, –Ω–æ –±–µ–∑ GPU\n"
                        "3. –ù–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞\n"
                        "4. –ù–µ –∑–Ω–∞—é / –Ω—É–∂–Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è",
                    ),
                    (
                        "–ï—Å—Ç—å VPS –Ω–∞ Ubuntu, –Ω–æ –±–µ–∑ GPU",
                        "–û—Ç–ª–∏—á–Ω–æ! –í–æ—Ç —á—Ç–æ –ø–æ–ª—É—á–∏—Ç—Å—è –Ω–∞ CPU:\n\n"
                        "üß† LLM: –æ–±–ª–∞—á–Ω—ã–π Gemini API (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∏—Ä)\n"
                        "üó£Ô∏è TTS: Piper (–±—ã—Å—Ç—Ä—ã–π, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ CPU)\n"
                        "üìä –ö–∞—á–µ—Å—Ç–≤–æ: —Ö–æ—Ä–æ—à–µ–µ ‚≠ê‚≠ê‚≠ê\n"
                        "‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: ~1-2 —Å–µ–∫ –Ω–∞ –æ—Ç–≤–µ—Ç\n\n"
                        "–≠—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ GPU –∏ –±–µ–∑ –∞–±–æ–Ω–µ–Ω—Ç—Å–∫–æ–π –ø–ª–∞—Ç—ã. "
                        "–•–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã —è —É—Å—Ç–∞–Ω–æ–≤–∏–ª? 5,000‚ÇΩ —Ä–∞–∑–æ–≤–æ.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –º–Ω–µ –Ω—É–∂–µ–Ω –≥–æ–ª–æ—Å–æ–≤–æ–π –±–æ—Ç –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∏–∏",
                        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! AI Secretary –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GSM-—Ç–µ–ª–µ—Ñ–æ–Ω–∏—é "
                        "—á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å SIM7600E-H.\n\n"
                        "–ë–æ—Ç –º–æ–∂–µ—Ç:\n"
                        "‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥—è—â–∏–µ –∑–≤–æ–Ω–∫–∏\n"
                        "‚Ä¢ –°–æ–≤–µ—Ä—à–∞—Ç—å –∏—Å—Ö–æ–¥—è—â–∏–µ\n"
                        "‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å SMS\n"
                        "‚Ä¢ –†–∞–±–æ—Ç–∞—Ç—å —Å –≤–∞—à–∏–º –≥–æ–ª–æ—Å–æ–º\n\n"
                        "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ ‚Äî "
                        "–∫–∞–∫–æ–π –æ–±—ä—ë–º –∑–≤–æ–Ω–∫–æ–≤ –≤ –¥–µ–Ω—å –∏ –∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ –Ω—É–∂–Ω–æ —Ä–µ—à–∏—Ç—å?",
                    ),
                    (
                        "–û–∫–æ–ª–æ 100 –∑–≤–æ–Ω–∫–æ–≤ –≤ –¥–µ–Ω—å, –∑–∞–ø–∏—Å—å –Ω–∞ –ø—Ä–∏—ë–º –≤ –∫–ª–∏–Ω–∏–∫—É",
                        "–û—Ç–ª–∏—á–Ω–∞—è –∑–∞–¥–∞—á–∞! –î–ª—è 100 –∑–≤–æ–Ω–∫–æ–≤/–¥–µ–Ω—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ –º–æ–¥—É–ª—è.\n\n"
                        "–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç:\n"
                        "‚Ä¢ –ë–∞–∑–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞: 50,000‚ÇΩ\n"
                        "‚Ä¢ GSM-–º–æ–¥—É–ª—å SIM7600E-H: ~5,000‚ÇΩ\n"
                        "‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∑–∞–ø–∏—Å–∏: 20,000‚ÇΩ\n"
                        "‚Ä¢ –ò—Ç–æ–≥–æ: 75,000-85,000‚ÇΩ\n\n"
                        "–°—Ä–æ–∫: 2-3 –Ω–µ–¥–µ–ª–∏. –•–æ—Ç–∏—Ç–µ –æ–±—Å—É–¥–∏—Ç—å –¥–µ—Ç–∞–ª–∏?",
                    ),
                ]
            )
        )

        # --- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ LLM –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è?",
                        "–õ–æ–∫–∞–ª—å–Ω—ã–µ (—á–µ—Ä–µ–∑ vLLM):\n"
                        "‚Ä¢ Qwen 2.5 (3B, 7B, 14B, 32B) ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º\n"
                        "‚Ä¢ Llama 3 (8B, 70B)\n"
                        "‚Ä¢ DeepSeek (7B, 67B)\n"
                        "‚Ä¢ Mistral, Phi, Gemma, Yi\n\n"
                        "–û–±–ª–∞—á–Ω—ã–µ:\n"
                        "‚Ä¢ Google Gemini (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∏—Ä)\n"
                        "‚Ä¢ OpenAI (GPT-4o)\n"
                        "‚Ä¢ Anthropic (Claude)\n"
                        "‚Ä¢ DeepSeek API\n"
                        "‚Ä¢ OpenRouter (200+ –º–æ–¥–µ–ª–µ–π)\n\n"
                        "–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ ‚Äî –æ–¥–Ω–∏–º –∫–ª–∏–∫–æ–º –≤ –∞–¥–º–∏–Ω–∫–µ.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞?",
                        "–ò—Å–ø–æ–ª—å–∑—É–µ–º XTTS v2 ‚Äî –æ–¥–Ω—É –∏–∑ –ª—É—á—à–∏—Ö open-source –º–æ–¥–µ–ª–µ–π.\n\n"
                        "–ü—Ä–æ—Ü–µ—Å—Å:\n"
                        "1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç–µ 3-5 –º–∏–Ω—É—Ç –∑–∞–ø–∏—Å–∏ –≤–∞—à–µ–≥–æ –≥–æ–ª–æ—Å–∞ (WAV)\n"
                        "2. –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ–∑–¥–∞—ë—Ç –≥–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å\n"
                        "3. AI –≥–æ–≤–æ—Ä–∏—Ç –≤–∞—à–∏–º –≥–æ–ª–æ—Å–æ–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n\n"
                        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n"
                        "‚Ä¢ GPU —Å 5+ –ì–ë VRAM (RTX 3060+)\n"
                        "‚Ä¢ –ß–∏—Å—Ç–∞—è –∑–∞–ø–∏—Å—å –±–µ–∑ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞\n\n"
                        "–î–ª—è CPU –µ—Å—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–∞ (Piper) ‚Äî "
                        "–º—É–∂—Å–∫–æ–π –∏ –∂–µ–Ω—Å–∫–∏–π, –±–µ–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ï—Å—Ç—å –ª–∏ API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏?",
                        "–î–∞, –µ—Å—Ç—å OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API:\n\n"
                        "‚Ä¢ POST /v1/chat/completions ‚Äî —á–∞—Ç —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º\n"
                        "‚Ä¢ POST /v1/audio/speech ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏\n"
                        "‚Ä¢ GET /v1/models ‚Äî —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π\n\n"
                        "–ú–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –∫ OpenWebUI –∏–ª–∏ –ª—é–±–æ–º—É "
                        "OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º—É –∫–ª–∏–µ–Ω—Ç—É.\n\n"
                        "–¢–∞–∫–∂–µ –µ—Å—Ç—å ~130 admin API endpoint'–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ "
                        "—É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–æ–π. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ –∞–¥–º–∏–Ω–∫–µ.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –æ–±–Ω–æ–≤–ª—è—Ç—å —Å–∏—Å—Ç–µ–º—É?",
                        "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Docker ‚Äî –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π:\n\n"
                        "```\n"
                        "git pull\n"
                        "docker compose build --no-cache orchestrator\n"
                        "docker compose up -d\n"
                        "```\n\n"
                        "–î–∞–Ω–Ω—ã–µ (–ë–î, –≥–æ–ª–æ—Å–∞, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏) —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫–µ data/. "
                        "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∫–æ–¥.",
                    ),
                ]
            )
        )

        # --- Follow-up / —É–¥–µ—Ä–∂–∞–Ω–∏–µ ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–Ø –ø–æ–¥—É–º–∞—é",
                        "–ö–æ–Ω–µ—á–Ω–æ, –Ω–µ —Ç–æ—Ä–æ–ø–ª—é! –í–æ—Ç —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å—Å—è:\n\n"
                        "üìä –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —ç–∫–æ–Ω–æ–º–∏–∏: —Ç–∏–ø–∏—á–Ω—ã–π SaaS-–±–æ—Ç —Å—Ç–æ–∏—Ç 15,000‚ÇΩ/–º–µ—Å, "
                        "–∑–∞ 3 –≥–æ–¥–∞ —ç—Ç–æ 540,000‚ÇΩ. AI Secretary ‚Äî 5,000‚ÇΩ –æ–¥–∏–Ω —Ä–∞–∑.\n\n"
                        "üé¨ –î–µ–º–æ: –º–æ–≥—É –ø–æ–∫–∞–∑–∞—Ç—å –∞–¥–º–∏–Ω–∫—É –≤ –¥–µ–π—Å—Ç–≤–∏–∏\n\n"
                        "‚≠ê GitHub: –º–æ–∂–µ—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–æ–¥ –∏ –æ—Ç–∑—ã–≤—ã\n\n"
                        "–ù–∞–ø–∏—à–∏—Ç–µ, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã ‚Äî –ø–æ–º–æ–≥—É!",
                    ),
                ]
            )
        )

        logger.info(f"üìù –ò–∑ –¢–ó —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
        return dialogs

    async def _generate_from_faq(self) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∏–∞–ª–æ–≥–∏ –∏–∑ FAQ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î."""
        dialogs = []

        try:
            from db.integration import async_faq_manager

            faq_entries = await async_faq_manager.get_all()

            for question, answer in faq_entries.items():
                if question and answer:
                    dialogs.append(
                        self._make_dialog(
                            [
                                (question, answer),
                            ]
                        )
                    )

            logger.info(f"üìù –ò–∑ FAQ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å FAQ: {e}")

        return dialogs

    def _generate_from_docs(self) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ Q&A –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞."""
        dialogs = []

        # --- –ò–∑ CLAUDE.md ---
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –≤ Docker?",
                        "–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±:\n\n"
                        "```\n"
                        "cp .env.docker.example .env\n"
                        "docker compose up -d\n"
                        "```\n\n"
                        "–î–ª—è CPU-—Ä–µ–∂–∏–º–∞ (–±–µ–∑ GPU):\n"
                        "```\n"
                        "docker compose -f docker-compose.yml "
                        "-f docker-compose.cpu.yml up -d\n"
                        "```\n\n"
                        "–õ–æ–≥–∏: `docker compose logs -f orchestrator`\n"
                        "–ê–¥–º–∏–Ω–∫–∞: http://localhost:8002/admin (admin/admin)",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç?",
                        "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è:\n"
                        "```\ncurl http://localhost:8002/health\n```\n\n"
                        '–ï—Å–ª–∏ –≤–µ—Ä–Ω—É–ª–æ—Å—å {"status": "ok"} ‚Äî —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç.\n\n'
                        "–¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∑–∞–π—Ç–∏ –≤ –∞–¥–º–∏–Ω–∫—É: http://localhost:8002/admin\n"
                        "–õ–æ–≥–∏–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: admin / admin",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å LLM-–±—ç–∫–µ–Ω–¥?",
                        "–í –∞–¥–º–∏–Ω–∫–µ ‚Üí –≤–∫–ª–∞–¥–∫–∞ LLM ‚Üí –≤—ã–±–µ—Ä–∏—Ç–µ –±—ç–∫–µ–Ω–¥:\n\n"
                        "‚Ä¢ vllm ‚Äî –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (–Ω—É–∂–µ–Ω GPU)\n"
                        "‚Ä¢ gemini ‚Äî Google Gemini API\n"
                        "‚Ä¢ cloud:{id} ‚Äî –ª—é–±–æ–π –æ–±–ª–∞—á–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞\n\n"
                        "–ò–ª–∏ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è:\n"
                        "```\nLLM_BACKEND=vllm  # –∏–ª–∏ gemini, cloud:openrouter-1\n```\n\n"
                        "–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –±–µ–∑ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ ‚Äî –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–æ.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –æ–±–ª–∞—á–Ω–æ–≥–æ LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞?",
                        "–í –∞–¥–º–∏–Ω–∫–µ ‚Üí LLM ‚Üí Cloud Providers ‚Üí –î–æ–±–∞–≤–∏—Ç—å:\n\n"
                        "1. –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø (Gemini, OpenAI, Claude, DeepSeek, OpenRouter, Kimi)\n"
                        "2. –í–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á\n"
                        "3. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å\n"
                        "4. –ù–∞–∂–º–∏—Ç–µ –¢–µ—Å—Ç ‚Üí –°–æ—Ö—Ä–∞–Ω–∏—Ç—å\n\n"
                        "–î–ª—è OpenRouter –µ—Å—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏. "
                        "–î–ª—è Gemini –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å VLESS-–ø—Ä–æ–∫—Å–∏.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Telegram-–±–æ—Ç–∞?",
                        "–í –∞–¥–º–∏–Ω–∫–µ ‚Üí Telegram ‚Üí –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç–∞–Ω—Å:\n\n"
                        "1. –°–æ–∑–¥–∞–π—Ç–µ –±–æ—Ç–∞ —É @BotFather ‚Üí –ø–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω\n"
                        "2. –í –∞–¥–º–∏–Ω–∫–µ: –î–æ–±–∞–≤–∏—Ç—å ‚Üí –≤—Å—Ç–∞–≤—å—Ç–µ —Ç–æ–∫–µ–Ω\n"
                        "3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ: –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –∫–Ω–æ–ø–∫–∏, LLM-–±—ç–∫–µ–Ω–¥\n"
                        "4. –ù–∞–∂–º–∏—Ç–µ –°—Ç–∞—Ä—Ç\n\n"
                        "–ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ —Å–∏—Å—Ç–µ–º—ã. "
                        "–ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–æ—Ç–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –≤–∏–¥–∂–µ—Ç —á–∞—Ç–∞ –Ω–∞ —Å–∞–π—Ç?",
                        "–í –∞–¥–º–∏–Ω–∫–µ ‚Üí –í–∏–¥–∂–µ—Ç ‚Üí –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç–∞–Ω—Å:\n\n"
                        "1. –£–∫–∞–∂–∏—Ç–µ –∏–º—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
                        "2. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç\n"
                        "3. –í—Å—Ç–∞–≤—å—Ç–µ –µ–≥–æ –Ω–∞ –≤–∞—à —Å–∞–π—Ç –ø–µ—Ä–µ–¥ </body>\n\n"
                        "–í–∏–¥–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ. "
                        "–ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∏–¥–∂–µ—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–∞–π—Ç–æ–≤.",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è?",
                        "SQLite + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π Redis.\n\n"
                        "‚Ä¢ SQLite: –æ—Å–Ω–æ–≤–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (data/secretary.db)\n"
                        "  –¢–∞–±–ª–∏—Ü—ã: —á–∞—Ç—ã, FAQ, –ø—Ä–µ—Å–µ—Ç—ã TTS, –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã LLM, "
                        "–±–æ—Ç—ã, –≤–∏–¥–∂–µ—Ç—ã, –∞—É–¥–∏—Ç\n\n"
                        "‚Ä¢ Redis: –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n"
                        "  –ï—Å–ª–∏ Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –Ω–µ–≥–æ\n\n"
                        "–ë—ç–∫–∞–ø—ã: cp data/secretary.db data/backup/",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ö–∞–∫ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö?",
                        "–í –∞–¥–º–∏–Ω–∫–µ ‚Üí –û–±—É—á–µ–Ω–∏–µ (Fine-tune):\n\n"
                        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ Telegram-—ç–∫—Å–ø–æ—Ä—Ç (result.json) –∏–ª–∏ "
                        "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞\n"
                        "2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (LoRA rank, epochs)\n"
                        "3. –ù–∞–∂–º–∏—Ç–µ Start ‚Äî –æ–±—É—á–µ–Ω–∏–µ –∏–¥—ë—Ç –Ω–∞ –≤–∞—à–µ–º GPU\n"
                        "4. –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ‚Äî –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –∞–¥–∞–ø—Ç–µ—Ä\n\n"
                        "–¢—Ä–µ–±—É–µ—Ç—Å—è GPU (RTX 3060+) –∏ train_venv. "
                        "–û–±—É—á–µ–Ω–∏–µ –Ω–∞ ~2000 –¥–∏–∞–ª–æ–≥–æ–≤ –∑–∞–Ω–∏–º–∞–µ—Ç 1-2 —á–∞—Å–∞.",
                    ),
                ]
            )
        )

        logger.info(f"üìù –ò–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
        return dialogs

    def _generate_escalation_examples(self) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –Ω–∞ —Å—Ç–∞—Ä—à–∏–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–¥–¥–µ—Ä–∂–∫–∏."""
        dialogs = []

        # –°–ª–æ–∂–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–£ –º–µ–Ω—è —Å–ª–æ–∂–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CRM —á–µ—Ä–µ–∑ webhook, –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–∏—Ö–æ–¥—è—Ç",
                        "–≠—Ç–æ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ª—É—á–∞–π, –ø–æ–¥–∫–ª—é—á–∞—é —Å—Ç–∞—Ä—à–µ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞. "
                        "–û–Ω —Å–≤—è–∂–µ—Ç—Å—è —Å –≤–∞–º–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ 15 –º–∏–Ω—É—Ç.\n\n"
                        "–ü–æ–∫–∞ –º–æ–∂–µ—Ç–µ –æ–ø–∏—Å–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ:\n"
                        "‚Ä¢ –ö–∞–∫–∞—è CRM (Bitrix, amoCRM, –¥—Ä—É–≥–∞—è)?\n"
                        "‚Ä¢ –ö–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Ö–æ–¥–∏—Ç—å?\n"
                        "‚Ä¢ –ï—Å—Ç—å –ª–∏ –ª–æ–≥–∏ –æ—à–∏–±–æ–∫?\n\n"
                        "–≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç —Ä–µ—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å –±—ã—Å—Ç—Ä–µ–µ.",
                    ),
                ]
            )
        )

        # –ù–µ–ø–æ–Ω—è—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π CUDA out of memory",
                        "–ü–æ—Ö–æ–∂–µ, –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏. –ü–∞—Ä–∞ –±—ã—Å—Ç—Ä—ã—Ö —Å–æ–≤–µ—Ç–æ–≤:\n\n"
                        "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ –ª–∏ —á—Ç–æ-—Ç–æ –µ—â—ë –Ω–∞ GPU: `nvidia-smi`\n"
                        "‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –º–æ–¥–µ–ª—å –ø–æ–º–µ–Ω—å—à–µ –≤ .env\n\n"
                        "–ï—Å–ª–∏ –Ω–µ –ø–æ–º–æ–∂–µ—Ç ‚Äî –ø–æ–¥–∫–ª—é—á—É —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞. "
                        "–°–∫–∞–∂–∏—Ç–µ, –∫–∞–∫–∞—è —É –≤–∞—Å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞ –∏ —Å–∫–æ–ª—å–∫–æ VRAM?",
                    ),
                ]
            )
        )

        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏, Vosk –≤—ã–¥–∞—ë—Ç –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
                        "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–µ—â–µ–π:\n\n"
                        "1. –ú–æ–¥–µ–ª—å Vosk —Å–∫–∞—á–∞–Ω–∞: `ls models/vosk/`\n"
                        "2. –§–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ: WAV, 16kHz, mono\n"
                        "3. –ú–∏–∫—Ä–æ—Ñ–æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç: –∑–∞–ø–∏—à–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ\n\n"
                        "–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –æ—Å—Ç–∞—ë—Ç—Å—è ‚Äî —ç—Ç–æ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ª—É—á–∞–π. "
                        "–ü–æ–¥–∫–ª—é—á—É —Å—Ç–∞—Ä—à–µ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏. "
                        "–ü—Ä–∏—à–ª–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ª–æ–≥ –æ—à–∏–±–∫–∏.",
                    ),
                ]
            )
        )

        # –ó–∞–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ú–æ–∂–µ—Ç–µ –ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥ –Ω–∞ Python?",
                        "–Ø —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ AI Secretary ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–º AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–µ. "
                        "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ–º–æ—á—å —Å –æ–±—â–∏–º–∏ –∑–∞–¥–∞—á–∞–º–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ —Å–º–æ–≥—É.\n\n"
                        "–ù–æ –µ—Å–ª–∏ –≤–∞—à –≤–æ–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π "
                        "AI Secretary ‚Äî —Å —Ä–∞–¥–æ—Å—Ç—å—é –ø–æ–º–æ–≥—É!\n\n"
                        "–ß–µ–º –µ—â—ë –º–æ–≥—É –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω?",
                    ),
                ]
            )
        )

        # –ñ–∞–ª–æ–±–∞ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –µ—Ä—É–Ω–¥—É, –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ —É–∂–∞—Å–Ω–æ–µ",
                        "–ü–æ–Ω–∏–º–∞—é –≤–∞—à–µ —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä—ë–º—Å—è:\n\n"
                        "1. –ö–∞–∫–∞—è –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è? (–ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –≤ –∞–¥–º–∏–Ω–∫–µ ‚Üí LLM)\n"
                        "2. –ï—Å—Ç—å –ª–∏ –æ–±—É—á–µ–Ω–Ω—ã–π LoRA-–∞–¥–∞–ø—Ç–µ—Ä?\n"
                        "3. –ó–∞–ø–æ–ª–Ω–µ–Ω –ª–∏ FAQ –¥–ª—è —Ç–∏–ø–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤?\n\n"
                        "–û–±—ã—á–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ:\n"
                        "‚Ä¢ –î–æ–±–∞–≤–ª–µ–Ω–∏—è FAQ (–º–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ —Ç–æ—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã)\n"
                        "‚Ä¢ –î–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n"
                        "‚Ä¢ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å\n\n"
                        "–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ ‚Äî –ø–æ–¥–∫–ª—é—á—É —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏. "
                        "–ò–ª–∏ —Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∏ —è –ø–æ–¥—Å–∫–∞–∂—É —á—Ç–æ —É–ª—É—á—à–∏—Ç—å.",
                    ),
                ]
            )
        )

        # –ó–∞–ø—Ä–æ—Å –Ω–∞ –±–æ–ª—å—à–æ–π –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–µ–∫—Ç
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–ù–∞–º –Ω—É–∂–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å —Å–∏—Å—Ç–µ–º—É –Ω–∞ 10 —Å–µ—Ä–≤–µ—Ä–∞—Ö —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π",
                        "–≠—Ç–æ enterprise-–∑–∞–¥–∞—á–∞, —Ç—Ä–µ–±—É–µ—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞.\n\n"
                        "–ü–µ—Ä–µ–¥–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å –Ω–∞—à–µ–º—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä—É. "
                        "–û–Ω —Å–≤—è–∂–µ—Ç—Å—è —Å –≤–∞–º–∏ –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è:\n\n"
                        "‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è\n"
                        "‚Ä¢ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏\n"
                        "‚Ä¢ –û—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏\n"
                        "‚Ä¢ –°—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ —Å—Ä–æ–∫–æ–≤\n\n"
                        "–û—Å—Ç–∞–≤—å—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–æ–Ω—Ç–∞–∫—Ç –¥–ª—è —Å–≤—è–∑–∏ "
                        "(email –∏–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω).",
                    ),
                ]
            )
        )

        # –ù–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–†–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ ARM-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö? –•–æ—á—É –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ Raspberry Pi",
                        "–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç —Å–∏—Å—Ç–µ–º–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∞—Å—å "
                        "—Ç–æ–ª—å–∫–æ –Ω–∞ x86_64 (Intel/AMD). –ü–æ–¥–¥–µ—Ä–∂–∫–∞ ARM –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ –Ω–µ –∑–∞—è–≤–ª–µ–Ω–∞.\n\n"
                        "–£—Ç–æ—á–Ω—é —É —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∏ –≤–µ—Ä–Ω—É—Å—å —Å –æ—Ç–≤–µ—Ç–æ–º. "
                        "–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ ‚Äî –æ—Å—Ç–∞–≤—å—Ç–µ –∫–æ–Ω—Ç–∞–∫—Ç, –Ω–∞–ø–∏—à—É –∫–∞–∫ –ø–æ—è–≤–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.\n\n"
                        "–ö–∞–∫ –≤–∞—Ä–∏–∞–Ω—Ç, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU-—Ä–µ–∂–∏–º —Å –æ–±–ª–∞—á–Ω—ã–º LLM ‚Äî "
                        "–æ–Ω –º–µ–Ω–µ–µ —Ç—Ä–µ–±–æ–≤–∞—Ç–µ–ª–µ–Ω –∫ –∂–µ–ª–µ–∑—É.",
                    ),
                ]
            )
        )

        # –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å
        dialogs.append(
            self._make_dialog(
                [
                    (
                        "–°–ø–∞—Å–∏–±–æ, –≤—Å—ë –∑–∞—Ä–∞–±–æ—Ç–∞–ª–æ! –ö–ª–∞—Å—Å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç",
                        "–†–∞–¥, —á—Ç–æ –≤—Å—ë –ø–æ–ª—É—á–∏–ª–æ—Å—å! üéâ\n\n"
                        "–ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –ø–æ–ª–µ–∑–µ–Ω ‚Äî –±—É–¥—É –ø—Ä–∏–∑–Ω–∞—Ç–µ–ª–µ–Ω –∑–∞ –∑–≤–µ–∑–¥—É –Ω–∞ GitHub ‚≠ê\n"
                        "github.com/ShaerWare/AI_Secretary_System\n\n"
                        "–ê –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç –≤–æ–ø—Ä–æ—Å—ã –≤ –±—É–¥—É—â–µ–º ‚Äî –ø–∏—à–∏—Ç–µ, –ø–æ–º–æ–≥—É!\n\n"
                        "–•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è!",
                    ),
                ]
            )
        )

        logger.info(f"üìù –≠—Å–∫–∞–ª–∞—Ü–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
        return dialogs

    # ============== Code & Documentation Parsing ==============

    def _generate_from_python_code(self) -> List[dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –ø–∞—Ä—ã –∏–∑ Python –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞.

        –ò—Å—Ç–æ—á–Ω–∏–∫–∏:
        - app/routers/*.py ‚Äî FastAPI endpoints —Å docstrings
        - db/models.py ‚Äî ORM –º–æ–¥–µ–ª–∏ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
        - vllm_llm_service.py ‚Äî SECRETARY_PERSONAS, PREDEFINED_MODELS
        - cloud_llm_service.py ‚Äî PROVIDER_TYPES
        """
        dialogs = []

        # 1. –ü–∞—Ä—Å–∏–º —Ä–æ—É—Ç–µ—Ä—ã (API endpoints)
        routers_dir = self.base_dir / "app" / "routers"
        if routers_dir.exists():
            for router_file in routers_dir.glob("*.py"):
                if router_file.name.startswith("__"):
                    continue
                try:
                    dialogs.extend(self._parse_router_file(router_file))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {router_file}: {e}")

        # 2. –ü–∞—Ä—Å–∏–º ORM –º–æ–¥–µ–ª–∏
        models_file = self.base_dir / "db" / "models.py"
        if models_file.exists():
            try:
                dialogs.extend(self._parse_orm_models(models_file))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ models.py: {e}")

        # 3. –ü–∞—Ä—Å–∏–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏
        for service_file in [
            "vllm_llm_service.py",
            "cloud_llm_service.py",
            "llm_service.py",
        ]:
            filepath = self.base_dir / service_file
            if filepath.exists():
                try:
                    dialogs.extend(self._parse_config_dicts(filepath))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {service_file}: {e}")

        # 4. –ü–∞—Ä—Å–∏–º orchestrator.py (Pydantic models)
        orchestrator_file = self.base_dir / "orchestrator.py"
        if orchestrator_file.exists():
            try:
                dialogs.extend(self._parse_pydantic_models(orchestrator_file))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ orchestrator.py: {e}")

        logger.info(f"üìù –ò–∑ Python –∫–æ–¥–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
        return dialogs

    def _parse_router_file(self, filepath: Path) -> List[dict]:
        """–ü–∞—Ä—Å–∏—Ç FastAPI —Ä–æ—É—Ç–µ—Ä –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç endpoint –æ–ø–∏—Å–∞–Ω–∏—è."""
        dialogs = []
        content = filepath.read_text(encoding="utf-8")
        tree = ast.parse(content)

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # –ò—â–µ–º –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã @router.get/post/put/delete
                for decorator in node.decorator_list:
                    method, path = self._extract_route_info(decorator)
                    if method and path:
                        docstring = ast.get_docstring(node)
                        func_name = node.name

                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Q&A –ø–∞—Ä—É
                        if docstring:
                            q = f"–ß—Ç–æ –¥–µ–ª–∞–µ—Ç endpoint {method.upper()} {path}?"
                            a = f"Endpoint {method.upper()} {path} ({func_name}):\n{docstring}"
                            dialogs.append(self._make_dialog([(q, a)]))

                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—Ä–∞ –ø—Ä–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
                        if docstring and len(docstring) > 20:
                            q2 = f"–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å API {path}?"
                            a2 = f"–í—ã–∑–æ–≤–∏—Ç–µ {method.upper()} {path}.\n\n{docstring}"
                            dialogs.append(self._make_dialog([(q2, a2)]))

        return dialogs

    def _extract_route_info(self, decorator: ast.expr) -> Tuple[Optional[str], Optional[str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç HTTP –º–µ—Ç–æ–¥ –∏ –ø—É—Ç—å –∏–∑ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ —Ä–æ—É—Ç–µ—Ä–∞."""
        try:
            if isinstance(decorator, ast.Call):
                if isinstance(decorator.func, ast.Attribute):
                    method = decorator.func.attr  # get, post, put, delete
                    if method in ("get", "post", "put", "delete", "patch"):
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞
                        if decorator.args:
                            if isinstance(decorator.args[0], ast.Constant):
                                path = decorator.args[0].value
                                return method, path
        except Exception:
            pass
        return None, None

    def _parse_orm_models(self, filepath: Path) -> List[dict]:
        """–ü–∞—Ä—Å–∏—Ç ORM –º–æ–¥–µ–ª–∏ (SQLAlchemy) –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü."""
        dialogs = []
        content = filepath.read_text(encoding="utf-8")
        tree = ast.parse(content)

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ SQLAlchemy –º–æ–¥–µ–ª—å (–Ω–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç Base)
                is_model = any(
                    (isinstance(base, ast.Name) and base.id == "Base")
                    or (isinstance(base, ast.Attribute) and base.attr == "Base")
                    for base in node.bases
                )

                if is_model:
                    class_name = node.name
                    docstring = ast.get_docstring(node)

                    # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª—è –º–æ–¥–µ–ª–∏
                    fields = []
                    for item in node.body:
                        if isinstance(item, ast.Assign):
                            for target in item.targets:
                                if isinstance(target, ast.Name):
                                    fields.append(target.id)
                        elif isinstance(item, ast.AnnAssign) and isinstance(item.target, ast.Name):
                            fields.append(item.target.id)

                    if fields:
                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
                        visible_fields = [
                            f for f in fields if not f.startswith("_") and f != "__tablename__"
                        ]

                        q = f"–ö–∞–∫–∏–µ –ø–æ–ª—è –µ—Å—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–µ {class_name}?"
                        a = f"–¢–∞–±–ª–∏—Ü–∞ {class_name} —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª—è:\n‚Ä¢ " + "\n‚Ä¢ ".join(
                            visible_fields[:15]
                        )
                        if docstring:
                            a += f"\n\n–û–ø–∏—Å–∞–Ω–∏–µ: {docstring}"
                        dialogs.append(self._make_dialog([(q, a)]))

        return dialogs

    def _parse_config_dicts(self, filepath: Path) -> List[dict]:
        """–ü–∞—Ä—Å–∏—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –∏–∑ —Å–µ—Ä–≤–∏—Å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""
        dialogs = []
        content = filepath.read_text(encoding="utf-8")

        # –ò—â–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏
        config_patterns = [
            (
                r"SECRETARY_PERSONAS\s*=\s*\{([^}]+)\}",
                "–ö–∞–∫–∏–µ –ø–µ—Ä—Å–æ–Ω—ã —Å–µ–∫—Ä–µ—Ç–∞—Ä—è –¥–æ—Å—Ç—É–ø–Ω—ã?",
                "–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω—ã —Å–µ–∫—Ä–µ—Ç–∞—Ä—è:\n",
            ),
            (
                r"PROVIDER_TYPES\s*=\s*\{([^}]+)\}",
                "–ö–∞–∫–∏–µ —Ç–∏–ø—ã –æ–±–ª–∞—á–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è?",
                "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –æ–±–ª–∞—á–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã:\n",
            ),
            (
                r"PREDEFINED_MODELS\s*=\s*\{([^}]+)\}",
                "–ö–∞–∫–∏–µ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è vLLM?",
                "–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n",
            ),
        ]

        for pattern, question, answer_prefix in config_patterns:
            match = re.search(pattern, content, re.DOTALL)
            if match:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                dict_content = match.group(1)
                keys = re.findall(r'"([^"]+)":', dict_content)
                if not keys:
                    keys = re.findall(r"'([^']+)':", dict_content)

                if keys:
                    answer = answer_prefix + "‚Ä¢ " + "\n‚Ä¢ ".join(keys[:10])
                    dialogs.append(self._make_dialog([(question, answer)]))

        # –ü–∞—Ä—Å–∏–º docstrings —Ñ—É–Ω–∫—Ü–∏–π
        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    docstring = ast.get_docstring(node)
                    if docstring and len(docstring) > 50:
                        func_name = node.name
                        if not func_name.startswith("_"):
                            q = f"–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—è {func_name}?"
                            a = f"–§—É–Ω–∫—Ü–∏—è {func_name}:\n{docstring[:500]}"
                            dialogs.append(self._make_dialog([(q, a)]))
        except Exception:
            pass

        return dialogs

    def _parse_pydantic_models(self, filepath: Path) -> List[dict]:
        """–ü–∞—Ä—Å–∏—Ç Pydantic –º–æ–¥–µ–ª–∏ (Request/Response) –∏–∑ —Ñ–∞–π–ª–∞."""
        dialogs = []
        content = filepath.read_text(encoding="utf-8")
        tree = ast.parse(content)

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ Pydantic –º–æ–¥–µ–ª—å (–Ω–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç BaseModel)
                is_pydantic = any(
                    (isinstance(base, ast.Name) and base.id == "BaseModel")
                    or (isinstance(base, ast.Attribute) and base.attr == "BaseModel")
                    for base in node.bases
                )

                if is_pydantic:
                    class_name = node.name
                    docstring = ast.get_docstring(node)

                    # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª—è —Å —Ç–∏–ø–∞–º–∏
                    fields = []
                    for item in node.body:
                        if isinstance(item, ast.AnnAssign) and isinstance(item.target, ast.Name):
                            field_name = item.target.id
                            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç–∏–ø
                            type_str = ast.unparse(item.annotation) if item.annotation else "Any"
                            fields.append(f"{field_name}: {type_str}")

                    if fields and ("Request" in class_name or "Response" in class_name):
                        q = f"–ö–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏–Ω–∏–º–∞–µ—Ç {class_name}?"
                        a = f"–ú–æ–¥–µ–ª—å {class_name}:\n‚Ä¢ " + "\n‚Ä¢ ".join(fields[:10])
                        if docstring:
                            a = f"{docstring}\n\n–ü–æ–ª—è:\n‚Ä¢ " + "\n‚Ä¢ ".join(fields[:10])
                        dialogs.append(self._make_dialog([(q, a)]))

        return dialogs

    def _generate_from_markdown_docs(self) -> List[dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –ø–∞—Ä—ã –∏–∑ Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞.

        –ò—Å—Ç–æ—á–Ω–∏–∫–∏:
        - README.md, CLAUDE.md, QUICKSTART.md
        - wiki-pages/*.md
        - examples.md, CHEATSHEET.md
        """
        dialogs = []

        # –°–ø–∏—Å–æ–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        main_docs = [
            "README.md",
            "QUICKSTART.md",
            "CHEATSHEET.md",
            "examples.md",
        ]

        for doc_name in main_docs:
            doc_path = self.base_dir / doc_name
            if doc_path.exists():
                try:
                    dialogs.extend(self._parse_markdown_file(doc_path))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {doc_name}: {e}")

        # –ü–∞—Ä—Å–∏–º wiki-pages
        wiki_dir = self.base_dir / "wiki-pages"
        if wiki_dir.exists():
            for wiki_file in wiki_dir.glob("*.md"):
                try:
                    dialogs.extend(self._parse_markdown_file(wiki_file))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {wiki_file.name}: {e}")

        logger.info(f"üìù –ò–∑ Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤")
        return dialogs

    def _parse_markdown_file(self, filepath: Path) -> List[dict]:
        """–ü–∞—Ä—Å–∏—Ç Markdown —Ñ–∞–π–ª –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –ø–∞—Ä—ã."""
        dialogs = []
        content = filepath.read_text(encoding="utf-8")
        filename = filepath.stem

        # 1. –ü–∞—Ä—Å–∏–º —Å–µ–∫—Ü–∏–∏ (## –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        sections = self._split_md_by_headers(content)
        for header, body in sections:
            if len(body.strip()) > 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                dialogs.extend(self._generate_qa_from_section(header, body, filename))

        # 2. –ü–∞—Ä—Å–∏–º code blocks
        code_blocks = self._extract_code_blocks(content)
        for lang, code in code_blocks:
            if len(code.strip()) > 20:
                dialogs.extend(self._generate_qa_from_code(lang, code, filename))

        # 3. –ü–∞—Ä—Å–∏–º —Ç–∞–±–ª–∏—Ü—ã
        tables = self._extract_md_tables(content)
        for table_header, table_content in tables:
            dialogs.extend(self._generate_qa_from_table(table_header, table_content))

        return dialogs

    def _split_md_by_headers(self, content: str) -> List[Tuple[str, str]]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç Markdown –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º ## –∏ ###."""
        sections = []
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —É—Ä–æ–≤–Ω—è 2 –∏ 3
        pattern = r"^(#{2,3})\s+(.+?)$"

        lines = content.split("\n")
        current_header = ""
        current_body = []

        for line in lines:
            match = re.match(pattern, line)
            if match:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–µ–∫—Ü–∏—é
                if current_header and current_body:
                    sections.append((current_header, "\n".join(current_body)))
                current_header = match.group(2).strip()
                current_body = []
            else:
                current_body.append(line)

        # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å–µ–∫—Ü–∏—è
        if current_header and current_body:
            sections.append((current_header, "\n".join(current_body)))

        return sections

    def _generate_qa_from_section(self, header: str, body: str, filename: str) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –ø–∞—Ä—ã –∏–∑ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        dialogs = []

        # –û—á–∏—â–∞–µ–º body –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        body = body.strip()
        if len(body) < 30:
            return dialogs

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
        if len(body) > 1500:
            body = body[:1500] + "..."

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
        header_lower = header.lower()

        if any(kw in header_lower for kw in ["install", "setup", "—É—Å—Ç–∞–Ω–æ–≤–∫", "–Ω–∞—Å—Ç—Ä–æ–π–∫", "–∑–∞–ø—É—Å–∫"]):
            q = f"–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å/—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {header}?"
        elif any(kw in header_lower for kw in ["api", "endpoint", "route"]):
            q = f"–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å API {header}?"
        elif any(
            kw in header_lower for kw in ["troubleshoot", "problem", "error", "–æ—à–∏–±–∫", "–ø—Ä–æ–±–ª–µ–º"]
        ):
            q = f"–ö–∞–∫ —Ä–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É —Å {header}?"
        elif any(kw in header_lower for kw in ["feature", "–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç", "—Ñ—É–Ω–∫—Ü–∏"]):
            q = f"–ö–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –µ—Å—Ç—å —É {header}?"
        elif any(kw in header_lower for kw in ["require", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "prerequisite"]):
            q = f"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è {header}?"
        else:
            q = f"–ß—Ç–æ —Ç–∞–∫–æ–µ {header}?"

        dialogs.append(self._make_dialog([(q, body)]))
        return dialogs

    def _extract_code_blocks(self, content: str) -> List[Tuple[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç code blocks –∏–∑ Markdown."""
        blocks = []
        pattern = r"```(\w*)\n(.*?)```"
        matches = re.findall(pattern, content, re.DOTALL)
        for lang, code in matches:
            if lang in ("bash", "python", "sh", "shell", ""):
                blocks.append((lang or "bash", code.strip()))
        return blocks[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

    def _generate_qa_from_code(self, lang: str, code: str, filename: str) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –∏–∑ code block."""
        dialogs = []

        # –¢–æ–ª—å–∫–æ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–º–∞–Ω–¥
        if len(code) > 500 or len(code) < 10:
            return dialogs

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–º–∞–Ω–¥—ã
        if lang in ("bash", "sh", "shell", ""):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—É—é –∫–æ–º–∞–Ω–¥—É
            first_line = code.split("\n", maxsplit=1)[0].strip()
            if first_line.startswith("#"):
                return dialogs

            if "docker" in first_line:
                q = "–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ Docker?"
            elif "curl" in first_line:
                q = "–ö–∞–∫ –≤—ã–∑–≤–∞—Ç—å API —á–µ—Ä–µ–∑ curl?"
            elif "git" in first_line:
                q = "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º?"
            elif "pip" in first_line or "npm" in first_line:
                q = "–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏?"
            elif "pytest" in first_line:
                q = "–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã?"
            else:
                q = f"–ü—Ä–∏–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –∏–∑ {filename}"

            a = f"```{lang}\n{code}\n```"
            dialogs.append(self._make_dialog([(q, a)]))

        return dialogs

    def _extract_md_tables(self, content: str) -> List[Tuple[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–∑ Markdown."""
        tables = []
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ç–∞–±–ª–∏—Ü
        pattern = r"(\|.+\|)\n(\|[-:| ]+\|)\n((?:\|.+\|\n?)+)"
        matches = re.findall(pattern, content)

        for header_row, sep_row, body_rows in matches:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫
            headers = [h.strip() for h in header_row.split("|") if h.strip()]
            if headers:
                table_content = header_row + "\n" + sep_row + "\n" + body_rows
                tables.append((", ".join(headers[:3]), table_content))

        return tables[:10]

    def _generate_qa_from_table(self, table_header: str, table_content: str) -> List[dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Q&A –∏–∑ —Ç–∞–±–ª–∏—Ü—ã."""
        dialogs = []

        if len(table_content) > 1000:
            return dialogs

        q = f"–ö–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã/–æ–ø—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã ({table_header})?"
        a = table_content
        dialogs.append(self._make_dialog([(q, a)]))

        return dialogs

    # ============== Training Configuration ==============

    def get_config(self) -> TrainingConfig:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è"""
        if self.training_config:
            return self.training_config

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        config_file = self.finetune_dir / "training_config.json"
        if config_file.exists():
            try:
                data = json.loads(config_file.read_text())
                self.training_config = TrainingConfig(**data)
            except Exception:
                self.training_config = TrainingConfig()
        else:
            self.training_config = TrainingConfig()

        return self.training_config

    def set_config(self, config: TrainingConfig) -> dict:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è"""
        self.training_config = config

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        config_file = self.finetune_dir / "training_config.json"
        try:
            config_file.write_text(json.dumps(asdict(config), indent=2))
            logger.info(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_file}")
            return {"status": "ok", "config": asdict(config)}
        except Exception as e:
            return {"status": "error", "message": str(e)}

    def get_config_presets(self) -> Dict[str, TrainingConfig]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return {
            "quick": TrainingConfig(
                lora_rank=4,
                lora_alpha=8,
                batch_size=1,
                gradient_accumulation_steps=32,
                num_epochs=1,
                max_seq_length=512,
                output_dir="adapter-quick",
            ),
            "standard": TrainingConfig(
                lora_rank=8,
                lora_alpha=16,
                batch_size=1,
                gradient_accumulation_steps=64,
                num_epochs=1,
                max_seq_length=768,
                output_dir="adapter-standard",
            ),
            "thorough": TrainingConfig(
                lora_rank=16,
                lora_alpha=32,
                batch_size=1,
                gradient_accumulation_steps=128,
                num_epochs=2,
                max_seq_length=1024,
                output_dir="adapter-thorough",
            ),
        }

    # ============== Training Operations ==============

    async def start_training(self, config: Optional[TrainingConfig] = None) -> dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç train.py –∏–∑ finetune/
        """
        if self.training_process and self.training_process.poll() is None:
            return {"status": "error", "message": "–û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ"}

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –∏–ª–∏ —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if config:
            self.training_config = config
        elif not self.training_config:
            self.training_config = TrainingConfig()

        config = self.training_config

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        jsonl_files = list(self.datasets_dir.glob("*.jsonl"))
        if not jsonl_files:
            return {
                "status": "error",
                "message": "–î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ.",
            }

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        _train_file = max(jsonl_files, key=lambda f: f.stat().st_mtime)

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∞–¥–∞–ø—Ç–µ—Ä–∞
        output_dir = self.adapters_dir / config.output_dir
        output_dir.mkdir(parents=True, exist_ok=True)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É –æ–±—É—á–µ–Ω–∏—è
        python_path = self.VENV_PATH / "bin" / "python"
        if not python_path.exists():
            return {"status": "error", "message": f"venv –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.VENV_PATH}"}

        train_script = self.finetune_dir / self.TRAIN_SCRIPT
        if not train_script.exists():
            return {"status": "error", "message": f"–°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {train_script}"}

        # train.py –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ö–∞—Ä–¥–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é
        # –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        cmd = [str(python_path), str(train_script)]

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è GPU
        env = os.environ.copy()
        env["CUDA_VISIBLE_DEVICES"] = "1"
        env["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"

        try:
            # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ª–æ–≥
            with self._training_lock:
                self.training_log = []
                self.training_status = TrainingStatus(
                    is_running=True, total_epochs=config.num_epochs
                )
                self.training_start_time = datetime.now()

            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
            self.training_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=str(self.finetune_dir),
                env=env,
                text=True,
                bufsize=1,
            )

            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è —á—Ç–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞
            threading.Thread(target=self._read_training_output, daemon=True).start()

            logger.info(f"üéì –û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ: {' '.join(cmd[:5])}...")

            return {
                "status": "ok",
                "message": "–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ",
                "config": asdict(config),
                "pid": self.training_process.pid,
            }

        except Exception as e:
            with self._training_lock:
                self.training_status.is_running = False
                self.training_status.error = str(e)
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return {"status": "error", "message": str(e)}

    def _read_training_output(self):
        """–ß–∏—Ç–∞–µ—Ç –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –≤ —Ñ–æ–Ω–µ"""
        if not self.training_process:
            return

        # –†–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        step_pattern = re.compile(r"Step (\d+)/(\d+)")
        loss_pattern = re.compile(r"loss[=:\s]+([0-9.]+)", re.IGNORECASE)
        epoch_pattern = re.compile(r"Epoch (\d+)/(\d+)")
        lr_pattern = re.compile(r"lr[=:\s]+([0-9.e-]+)", re.IGNORECASE)

        for line in iter(self.training_process.stdout.readline, ""):
            if not line:
                break

            line = line.strip()

            with self._training_lock:
                self.training_log.append(line)

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ª–æ–≥–∞
                if len(self.training_log) > 10000:
                    self.training_log = self.training_log[-5000:]

                # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                step_match = step_pattern.search(line)
                if step_match:
                    self.training_status.current_step = int(step_match.group(1))
                    self.training_status.total_steps = int(step_match.group(2))

                loss_match = loss_pattern.search(line)
                if loss_match:
                    self.training_status.loss = float(loss_match.group(1))

                epoch_match = epoch_pattern.search(line)
                if epoch_match:
                    self.training_status.current_epoch = int(epoch_match.group(1))
                    self.training_status.total_epochs = int(epoch_match.group(2))

                lr_match = lr_pattern.search(line)
                if lr_match:
                    self.training_status.learning_rate = float(lr_match.group(1))

                # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è
                if self.training_start_time:
                    elapsed = (datetime.now() - self.training_start_time).total_seconds()
                    self.training_status.elapsed_seconds = elapsed

                    # ETA
                    if (
                        self.training_status.current_step > 0
                        and self.training_status.total_steps > 0
                    ):
                        steps_remaining = (
                            self.training_status.total_steps - self.training_status.current_step
                        )
                        time_per_step = elapsed / self.training_status.current_step
                        self.training_status.eta_seconds = steps_remaining * time_per_step

        # –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è
        with self._training_lock:
            self.training_status.is_running = False
            returncode = self.training_process.wait()
            if returncode != 0:
                self.training_status.error = f"–ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –∫–æ–¥–æ–º {returncode}"
            else:
                logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")

    async def stop_training(self) -> dict:
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ"""
        if not self.training_process or self.training_process.poll() is not None:
            return {"status": "ok", "message": "–û–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ"}

        try:
            self.training_process.terminate()
            try:
                self.training_process.wait(timeout=10)
            except subprocess.TimeoutExpired:
                self.training_process.kill()

            with self._training_lock:
                self.training_status.is_running = False

            logger.info("üõë –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            return {"status": "ok", "message": "–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"}

        except Exception as e:
            return {"status": "error", "message": str(e)}

    def get_training_status(self) -> TrainingStatus:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è"""
        with self._training_lock:
            return TrainingStatus(
                is_running=self.training_status.is_running,
                current_step=self.training_status.current_step,
                total_steps=self.training_status.total_steps,
                current_epoch=self.training_status.current_epoch,
                total_epochs=self.training_status.total_epochs,
                loss=self.training_status.loss,
                learning_rate=self.training_status.learning_rate,
                elapsed_seconds=self.training_status.elapsed_seconds,
                eta_seconds=self.training_status.eta_seconds,
                error=self.training_status.error,
            )

    def get_training_log(self, lines: int = 100, offset: int = 0) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–æ–≥ –æ–±—É—á–µ–Ω–∏—è"""
        with self._training_lock:
            total = len(self.training_log)
            if offset > 0:
                end_idx = max(0, total - offset)
                start_idx = max(0, end_idx - lines)
            else:
                start_idx = max(0, total - lines)
                end_idx = total

            return {
                "lines": self.training_log[start_idx:end_idx],
                "total_lines": total,
                "start_line": start_idx,
                "end_line": end_idx,
            }

    async def stream_training_log(self, interval: float = 0.5) -> AsyncGenerator[str, None]:
        """SSE streaming –ª–æ–≥–∞ –æ–±—É—á–µ–Ω–∏—è"""
        last_line_idx = 0

        while True:
            with self._training_lock:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                if len(self.training_log) > last_line_idx:
                    new_lines = self.training_log[last_line_idx:]
                    last_line_idx = len(self.training_log)

                    for line in new_lines:
                        yield json.dumps(
                            {"type": "log", "line": line, "timestamp": datetime.now().isoformat()}
                        )

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                yield json.dumps({"type": "status", "status": asdict(self.training_status)})

                is_running = self.training_status.is_running

            if not is_running:
                yield json.dumps({"type": "done"})
                break

            await asyncio.sleep(interval)

    # ============== Adapter Operations ==============

    def list_adapters(self) -> List[AdapterInfo]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤"""
        adapters = []

        if not self.adapters_dir.exists():
            return adapters

        for adapter_dir in self.adapters_dir.iterdir():
            if not adapter_dir.is_dir() or adapter_dir.name.startswith("."):
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –∞–¥–∞–ø—Ç–µ—Ä–∞
            adapter_files = list(adapter_dir.glob("adapter_*.safetensors")) + list(
                adapter_dir.glob("adapter_*.bin")
            )
            if not adapter_files:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–ø–∞–ø–∫—É final
                final_dir = adapter_dir / "final"
                if final_dir.exists():
                    adapter_files = list(final_dir.glob("adapter_*.safetensors")) + list(
                        final_dir.glob("adapter_*.bin")
                    )

            if not adapter_files:
                continue

            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä
            total_size = sum(f.stat().st_size for f in adapter_dir.rglob("*") if f.is_file())
            size_mb = total_size / (1024 * 1024)

            # –î–∞—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
            modified = datetime.fromtimestamp(adapter_dir.stat().st_mtime).isoformat()

            # –ö–æ–Ω—Ñ–∏–≥ –µ—Å–ª–∏ –µ—Å—Ç—å
            config = None
            config_file = adapter_dir / "adapter_config.json"
            if not config_file.exists():
                config_file = adapter_dir / "final" / "adapter_config.json"
            if config_file.exists():
                try:
                    config = json.loads(config_file.read_text())
                except Exception:
                    pass

            adapters.append(
                AdapterInfo(
                    name=adapter_dir.name,
                    path=str(adapter_dir),
                    size_mb=round(size_mb, 2),
                    modified=modified,
                    active=(adapter_dir.name == self.active_adapter),
                    config=config,
                )
            )

        return sorted(adapters, key=lambda x: x.modified, reverse=True)

    async def activate_adapter(self, adapter_name: str) -> dict:
        """
        –ê–∫—Ç–∏–≤–∏—Ä—É–µ—Ç LoRA –∞–¥–∞–ø—Ç–µ—Ä (hot-swap –≤ vLLM).
        """
        adapter_dir = self.adapters_dir / adapter_name
        if not adapter_dir.exists():
            return {"status": "error", "message": f"–ê–¥–∞–ø—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {adapter_name}"}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
        final_dir = adapter_dir / "final"
        if final_dir.exists():
            adapter_path = final_dir
        else:
            adapter_path = adapter_dir

        adapter_files = list(adapter_path.glob("adapter_*.safetensors")) + list(
            adapter_path.glob("adapter_*.bin")
        )
        if not adapter_files:
            return {"status": "error", "message": f"–§–∞–π–ª—ã –∞–¥–∞–ø—Ç–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {adapter_path}"}

        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å hot-swap —á–µ—Ä–µ–∑ vLLM API
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –∞–∫—Ç–∏–≤–Ω—ã–π
        self._save_active_adapter(adapter_name)

        logger.info(f"‚úÖ –ê–¥–∞–ø—Ç–µ—Ä –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω: {adapter_name}")

        return {
            "status": "ok",
            "message": f"–ê–¥–∞–ø—Ç–µ—Ä {adapter_name} –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ vLLM –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è.",
            "adapter": adapter_name,
            "path": str(adapter_path),
            "note": "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ vLLM –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∞–¥–∞–ø—Ç–µ—Ä–∞",
        }

    async def delete_adapter(self, adapter_name: str) -> dict:
        """–£–¥–∞–ª—è–µ—Ç LoRA –∞–¥–∞–ø—Ç–µ—Ä"""
        adapter_dir = self.adapters_dir / adapter_name
        if not adapter_dir.exists():
            return {"status": "error", "message": f"–ê–¥–∞–ø—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {adapter_name}"}

        if adapter_name == self.active_adapter:
            return {"status": "error", "message": "–ù–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä"}

        try:
            shutil.rmtree(adapter_dir)
            logger.info(f"üóëÔ∏è –ê–¥–∞–ø—Ç–µ—Ä —É–¥–∞–ª—ë–Ω: {adapter_name}")
            return {"status": "ok", "message": f"–ê–¥–∞–ø—Ç–µ—Ä {adapter_name} —É–¥–∞–ª—ë–Ω"}
        except Exception as e:
            return {"status": "error", "message": str(e)}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_finetune_manager: Optional[FinetuneManager] = None


def get_finetune_manager() -> FinetuneManager:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π FinetuneManager"""
    global _finetune_manager
    if _finetune_manager is None:
        _finetune_manager = FinetuneManager()
    return _finetune_manager


if __name__ == "__main__":
    import asyncio

    async def test():
        manager = FinetuneManager()

        print("=== Dataset Stats ===")
        stats = manager.get_dataset_stats()
        print(f"  Sessions: {stats.total_sessions}")
        print(f"  Messages: {stats.total_messages}")
        print(f"  Tokens: {stats.total_tokens}")

        print("\n=== Training Config ===")
        config = manager.get_config()
        print(f"  LoRA rank: {config.lora_rank}")
        print(f"  Batch size: {config.batch_size}")
        print(f"  Learning rate: {config.learning_rate}")

        print("\n=== Adapters ===")
        for adapter in manager.list_adapters():
            active = " (ACTIVE)" if adapter.active else ""
            print(f"  - {adapter.name}: {adapter.size_mb} MB{active}")

    asyncio.run(test())
