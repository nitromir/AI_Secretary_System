#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä - –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
STT (Whisper) -> LLM (Gemini) -> TTS (XTTS v2)
"""
from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.responses import FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import logging
from pathlib import Path
import tempfile
import os
from typing import Optional
from pydantic import BaseModel
import asyncio
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç—ã –Ω–∞—à–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
from voice_clone_service import VoiceCloneService
from stt_service import STTService
from llm_service import LLMService

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="AI Secretary Orchestrator", version="1.0.0")

# CORS –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
voice_service: Optional[VoiceCloneService] = None
stt_service: Optional[STTService] = None
llm_service: Optional[LLMService] = None

# –ü–∞–ø–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
TEMP_DIR = Path("./temp")
TEMP_DIR.mkdir(exist_ok=True)

# –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤ –∑–≤–æ–Ω–∫–æ–≤
CALLS_LOG_DIR = Path("./calls_log")
CALLS_LOG_DIR.mkdir(exist_ok=True)


class ConversationRequest(BaseModel):
    text: str
    session_id: Optional[str] = None


class TTSRequest(BaseModel):
    text: str
    language: str = "ru"


class OpenAISpeechRequest(BaseModel):
    """OpenAI-compatible TTS request for OpenWebUI integration"""
    model: str = "lidia-voice"
    input: str
    voice: str = "lidia"
    response_format: str = "wav"
    speed: float = 1.0


@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    global voice_service, stt_service, llm_service

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ AI Secretary Orchestrator")

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
        logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ Voice Clone Service...")
        voice_service = VoiceCloneService()

        logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ STT Service...")
        stt_service = STTService(model_size="base", use_faster_whisper=True)

        logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ LLM Service...")
        llm_service = LLMService()

        logger.info("‚úÖ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        raise


@app.get("/")
async def root():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"""
    return {
        "status": "ok",
        "service": "AI Secretary Orchestrator",
        "endpoints": {
            "health": "/health",
            "process_call": "/process_call (POST)",
            "tts": "/tts (POST)",
            "stt": "/stt (POST)",
            "chat": "/chat (POST)",
        }
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
    services_status = {
        "voice_clone": voice_service is not None,
        "stt": stt_service is not None,
        "llm": llm_service is not None,
    }

    all_ok = all(services_status.values())

    return {
        "status": "healthy" if all_ok else "degraded",
        "services": services_status,
        "timestamp": datetime.now().isoformat()
    }


@app.post("/tts")
async def text_to_speech(request: TTSRequest):
    """
    –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º –õ–∏–¥–∏–∏
    """
    if not voice_service:
        raise HTTPException(status_code=503, detail="Voice service not initialized")

    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        output_file = TEMP_DIR / f"tts_{datetime.now().timestamp()}.wav"

        # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º
        voice_service.synthesize_to_file(
            text=request.text,
            output_path=str(output_file),
            language=request.language
        )

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª
        return FileResponse(
            path=output_file,
            media_type="audio/wav",
            filename="response.wav"
        )

    except Exception as e:
        logger.error(f"‚ùå TTS Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/stt")
async def speech_to_text(audio: UploadFile = File(...)):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
    """
    if not stt_service:
        raise HTTPException(status_code=503, detail="STT service not initialized")

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_audio = TEMP_DIR / f"stt_{datetime.now().timestamp()}_{audio.filename}"

        with open(temp_audio, "wb") as f:
            content = await audio.read()
            f.write(content)

        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º
        result = stt_service.transcribe(temp_audio, language="ru")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_audio.unlink()

        return {
            "text": result["text"],
            "language": result["language"],
            "segments_count": len(result.get("segments", []))
        }

    except Exception as e:
        logger.error(f"‚ùå STT Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chat")
async def chat(request: ConversationRequest):
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM (Gemini)
    """
    if not llm_service:
        raise HTTPException(status_code=503, detail="LLM service not initialized")

    try:
        response = llm_service.generate_response(request.text)

        return {
            "response": response,
            "session_id": request.session_id
        }

    except Exception as e:
        logger.error(f"‚ùå LLM Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/process_call")
async def process_call(audio: UploadFile = File(...)):
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–≤–æ–Ω–∫–∞:
    1. STT - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
    2. LLM - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    3. TTS - —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞—É–¥–∏–æ —Å –æ—Ç–≤–µ—Ç–æ–º —Å–µ–∫—Ä–µ—Ç–∞—Ä—è
    """
    call_id = f"call_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    logger.info(f"üìû –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–≤–æ–Ω–∫–∞ {call_id}")

    try:
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥—è—â–∏–π –∞—É–¥–∏–æ
        input_audio = CALLS_LOG_DIR / f"{call_id}_input.wav"
        with open(input_audio, "wb") as f:
            content = await audio.read()
            f.write(content)

        # 2. –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å (STT)
        logger.info(f"üéß STT –¥–ª—è {call_id}")
        stt_result = stt_service.transcribe(input_audio, language="ru")
        recognized_text = stt_result["text"]
        logger.info(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {recognized_text}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        with open(CALLS_LOG_DIR / f"{call_id}_transcript.txt", "w") as f:
            f.write(f"USER: {recognized_text}\n")

        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (LLM)
        logger.info(f"ü§ñ LLM –¥–ª—è {call_id}")
        llm_response = llm_service.generate_response(recognized_text)
        logger.info(f"üí¨ –û—Ç–≤–µ—Ç: {llm_response}")

        # –î–æ–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        with open(CALLS_LOG_DIR / f"{call_id}_transcript.txt", "a") as f:
            f.write(f"ASSISTANT: {llm_response}\n")

        # 4. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (TTS)
        logger.info(f"üéôÔ∏è  TTS –¥–ª—è {call_id}")
        output_audio = CALLS_LOG_DIR / f"{call_id}_output.wav"
        voice_service.synthesize_to_file(
            text=llm_response,
            output_path=str(output_audio),
            language="ru"
        )

        logger.info(f"‚úÖ –ó–≤–æ–Ω–æ–∫ {call_id} –æ–±—Ä–∞–±–æ—Ç–∞–Ω")

        # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—É–¥–∏–æ –æ—Ç–≤–µ—Ç
        return FileResponse(
            path=output_audio,
            media_type="audio/wav",
            filename=f"{call_id}_response.wav",
            headers={
                "X-Call-ID": call_id,
                "X-Recognized-Text": recognized_text,
                "X-Response-Text": llm_response
            }
        )

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–≤–æ–Ω–∫–∞ {call_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/reset_conversation")
async def reset_conversation():
    """–°–±—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
    if llm_service:
        llm_service.reset_conversation()
        return {"status": "ok", "message": "Conversation history reset"}
    raise HTTPException(status_code=503, detail="LLM service not initialized")


# ============== OpenAI-Compatible Endpoints for OpenWebUI ==============

@app.get("/v1/models")
async def list_models():
    """OpenAI-compatible models list for OpenWebUI TTS integration"""
    return {
        "object": "list",
        "data": [
            {
                "id": "lidia-voice",
                "object": "model",
                "created": 1700000000,
                "owned_by": "ai-secretary",
                "permission": [],
                "root": "lidia-voice",
                "parent": None
            }
        ]
    }


@app.get("/v1/voices")
async def list_voices():
    """List available voices"""
    return {
        "voices": [
            {"voice_id": "lidia", "name": "–õ–∏–¥–∏—è", "language": "ru"}
        ]
    }


@app.post("/v1/audio/speech")
async def openai_speech(request: OpenAISpeechRequest):
    """
    OpenAI-compatible TTS endpoint for OpenWebUI integration
    POST /v1/audio/speech
    """
    if not voice_service:
        raise HTTPException(status_code=503, detail="Voice service not initialized")

    try:
        output_file = TEMP_DIR / f"speech_{datetime.now().timestamp()}.wav"

        voice_service.synthesize_to_file(
            text=request.input,
            output_path=str(output_file),
            language="ru"
        )

        return FileResponse(
            path=output_file,
            media_type="audio/wav",
            filename="speech.wav"
        )

    except Exception as e:
        logger.error(f"‚ùå OpenAI TTS Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    port = int(os.getenv("ORCHESTRATOR_PORT", 8002))
    logger.info(f"üéØ –ó–∞–ø—É—Å–∫ Orchestrator –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    uvicorn.run(
        "orchestrator:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        log_level="info"
    )
