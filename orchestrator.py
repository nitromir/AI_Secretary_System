#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä - –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
STT (Whisper) -> LLM (Gemini) -> TTS (XTTS v2)
"""
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import logging
from pathlib import Path
import os
from typing import Optional, List, Dict
from pydantic import BaseModel
from datetime import datetime
import json
import time
import threading
import hashlib
import re
import numpy as np
from collections import OrderedDict
import asyncio
from concurrent.futures import ThreadPoolExecutor
import soundfile as sf

# –ò–º–ø–æ—Ä—Ç—ã –Ω–∞—à–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
from voice_clone_service import VoiceCloneService
from stt_service import STTService
from llm_service import LLMService
from piper_tts_service import PiperTTSService

# vLLM –∏–º–ø–æ—Ä—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π - –ª–æ–∫–∞–ª—å–Ω–∞—è Llama —á–µ—Ä–µ–∑ vLLM)
try:
    from vllm_llm_service import VLLMLLMService
    VLLM_AVAILABLE = True
except ImportError:
    VLLM_AVAILABLE = False
    VLLMLLMService = None

# OpenVoice –∏–º–ø–æ—Ä—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π - –¥–ª—è GPU P104-100)
try:
    from openvoice_service import OpenVoiceService
    OPENVOICE_AVAILABLE = True
except ImportError:
    OPENVOICE_AVAILABLE = False
    OpenVoiceService = None

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π LLM backend –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
LLM_BACKEND = os.getenv("LLM_BACKEND", "gemini").lower()  # "gemini" –∏–ª–∏ "vllm"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============== Streaming TTS Manager ==============
class StreamingTTSManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ TTS –≤–æ –≤—Ä–µ–º—è streaming LLM.

    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    1. –í–æ –≤—Ä–µ–º—è streaming chat/completions - –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
       –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ç–µ–∑ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ
    2. –•—Ä–∞–Ω–∏–º —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –∫—ç—à–µ –ø–æ —Ö—ç—à—É –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    3. –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ /v1/audio/speech - —Å–∫–ª–µ–∏–≤–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    """

    def __init__(self, max_cache_size: int = 50, cache_ttl: int = 300):
        self.max_cache_size = max_cache_size
        self.cache_ttl = cache_ttl  # —Å–µ–∫—É–Ω–¥

        # –ö—ç—à: response_hash -> {"segments": [...], "full_audio": np.array, "timestamp": float}
        self._cache: OrderedDict[str, Dict] = OrderedDict()
        self._cache_lock = threading.Lock()

        # –¢–µ–∫—É—â–∏–µ —Å–µ—Å—Å–∏–∏ —Å–∏–Ω—Ç–µ–∑–∞: session_id -> {"text": str, "segments": [...], "futures": [...]}
        self._active_sessions: Dict[str, Dict] = {}
        self._session_lock = threading.Lock()

        # Thread pool –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞
        self._executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="tts_")

        # –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        self._sentence_pattern = re.compile(r'([^.!?]*[.!?]+)')

        logger.info("üéôÔ∏è StreamingTTSManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _get_text_hash(self, text: str) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö—ç—à —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        normalized = text.strip().lower()
        return hashlib.md5(normalized.encode()).hexdigest()[:16]

    def _clean_old_cache(self):
        """–£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫—ç—à–∞"""
        now = time.time()
        with self._cache_lock:
            keys_to_delete = []
            for key, value in self._cache.items():
                if now - value.get("timestamp", 0) > self.cache_ttl:
                    keys_to_delete.append(key)
            for key in keys_to_delete:
                del self._cache[key]
                logger.debug(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫—ç—à: {key}")

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            while len(self._cache) > self.max_cache_size:
                self._cache.popitem(last=False)

    def start_session(self, session_id: str) -> None:
        """–ù–∞—á–∏–Ω–∞–µ—Ç –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é streaming —Å–∏–Ω—Ç–µ–∑–∞"""
        with self._session_lock:
            self._active_sessions[session_id] = {
                "text_buffer": "",
                "full_text": "",
                "segments": [],  # [(text, audio_data, sample_rate), ...]
                "pending_futures": [],
                "start_time": time.time(),
            }
        logger.info(f"üé¨ –ù–∞—á–∞—Ç–∞ —Å–µ—Å—Å–∏—è TTS: {session_id}")

    def add_text_chunk(self, session_id: str, chunk: str, voice_service) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç chunk —Ç–µ–∫—Å—Ç–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–∏–Ω—Ç–µ–∑ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ streaming LLM response.
        """
        with self._session_lock:
            if session_id not in self._active_sessions:
                return

            session = self._active_sessions[session_id]
            session["text_buffer"] += chunk
            session["full_text"] += chunk

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            buffer = session["text_buffer"]
            sentences = self._sentence_pattern.findall(buffer)

            if sentences:
                # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) > 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
                        future = self._executor.submit(
                            self._synthesize_segment,
                            sentence,
                            voice_service,
                            session_id
                        )
                        session["pending_futures"].append((sentence, future))
                        logger.info(f"üîÑ –ó–∞–ø—É—â–µ–Ω —Å–∏–Ω—Ç–µ–∑: '{sentence[:40]}...'")

                # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –±—É—Ñ–µ—Ä–∞
                last_sentence = sentences[-1]
                idx = buffer.rfind(last_sentence) + len(last_sentence)
                session["text_buffer"] = buffer[idx:]

    def _synthesize_segment(self, text: str, voice_service, session_id: str) -> tuple:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ thread pool)"""
        try:
            wav, sr = voice_service.synthesize(
                text=text,
                preset="natural",
                preprocess_text=True,
                split_sentences=False  # –£–∂–µ —Ä–∞–∑–±–∏–ª–∏
            )
            logger.info(f"‚úÖ –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω —Å–µ–≥–º–µ–Ω—Ç: '{text[:30]}...'")
            return (text, wav, sr)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            return (text, None, None)

    def finish_session(self, session_id: str, voice_service) -> None:
        """
        –ó–∞–≤–µ—Ä—à–∞–µ—Ç —Å–µ—Å—Å–∏—é: —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
        """
        with self._session_lock:
            if session_id not in self._active_sessions:
                return

            session = self._active_sessions[session_id]

            # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –±—É—Ñ–µ—Ä–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
            remaining = session["text_buffer"].strip()
            if remaining and len(remaining) > 3:
                future = self._executor.submit(
                    self._synthesize_segment,
                    remaining,
                    voice_service,
                    session_id
                )
                session["pending_futures"].append((remaining, future))
                logger.info(f"üîÑ –ó–∞–ø—É—â–µ–Ω —Å–∏–Ω—Ç–µ–∑ –æ—Å—Ç–∞—Ç–∫–∞: '{remaining[:40]}...'")

            # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö futures
            for text, future in session["pending_futures"]:
                try:
                    result = future.result(timeout=60)
                    if result[1] is not None:
                        session["segments"].append(result)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–∏–Ω—Ç–µ–∑–∞: {e}")

            # –°–∫–ª–µ–∏–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
            full_text = session["full_text"]
            if session["segments"]:
                self._cache_full_audio(full_text, session["segments"])

            elapsed = time.time() - session["start_time"]
            logger.info(f"‚úÖ –°–µ—Å—Å–∏—è {session_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f}s, "
                       f"—Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(session['segments'])}")

            # –£–¥–∞–ª—è–µ–º —Å–µ—Å—Å–∏—é
            del self._active_sessions[session_id]

    def _cache_full_audio(self, full_text: str, segments: list) -> None:
        """–°–∫–ª–µ–∏–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –∏ –∫—ç—à–∏—Ä—É–µ—Ç –ø–æ–ª–Ω–æ–µ –∞—É–¥–∏–æ"""
        if not segments:
            return

        # –ü–æ–ª—É—á–∞–µ–º sample rate –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        sample_rate = segments[0][2]

        # –°–∫–ª–µ–∏–≤–∞–µ–º –∞—É–¥–∏–æ —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –ø–∞—É–∑–∞–º–∏
        pause_samples = int(0.1 * sample_rate)  # 100ms –ø–∞—É–∑–∞
        pause = np.zeros(pause_samples, dtype=np.float32)

        audio_parts = []
        for text, wav, sr in segments:
            if wav is not None:
                if isinstance(wav, list):
                    wav = np.array(wav, dtype=np.float32)
                audio_parts.append(wav)
                audio_parts.append(pause)

        if audio_parts:
            full_audio = np.concatenate(audio_parts[:-1])  # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞—É–∑—É

            text_hash = self._get_text_hash(full_text)
            with self._cache_lock:
                self._cache[text_hash] = {
                    "full_audio": full_audio,
                    "sample_rate": sample_rate,
                    "full_text": full_text,
                    "timestamp": time.time(),
                    "segments_count": len(segments),
                }
                logger.info(f"üíæ –ó–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–æ –∞—É–¥–∏–æ: {text_hash} ({len(full_audio)/sample_rate:.2f}s)")

            self._clean_old_cache()

    def get_cached_audio(self, text: str) -> Optional[tuple]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –¥–ª—è —Ç–µ–∫—Å—Ç–∞.
        Returns: (audio_data, sample_rate) –∏–ª–∏ None
        """
        text_hash = self._get_text_hash(text)

        with self._cache_lock:
            if text_hash in self._cache:
                cached = self._cache[text_hash]
                logger.info(f"‚ö° Cache HIT: {text_hash}")
                return (cached["full_audio"], cached["sample_rate"])

        logger.info(f"‚ùå Cache MISS: {text_hash}")
        return None

    def get_stats(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        with self._cache_lock:
            cache_size = len(self._cache)
        with self._session_lock:
            active_sessions = len(self._active_sessions)

        return {
            "cache_size": cache_size,
            "active_sessions": active_sessions,
            "max_cache_size": self.max_cache_size,
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä streaming TTS
streaming_tts_manager: Optional[StreamingTTSManager] = None

app = FastAPI(title="AI Secretary Orchestrator", version="1.0.0")

# CORS –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
voice_service: Optional[VoiceCloneService] = None  # XTTS (–õ–∏–¥–∏—è) - GPU CC >= 7.0
piper_service: Optional[PiperTTSService] = None    # Piper (Dmitri, Irina) - CPU
openvoice_service: Optional["OpenVoiceService"] = None  # OpenVoice v2 (–õ–∏–¥–∏—è) - GPU CC 6.1+
stt_service: Optional[STTService] = None
llm_service: Optional[LLMService] = None

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ–∫—É—â–µ–≥–æ –≥–æ–ª–æ—Å–∞
# engine: "xtts" (–õ–∏–¥–∏—è –Ω–∞ GPU CC>=7.0), "piper" (Dmitri/Irina –Ω–∞ CPU), "openvoice" (–õ–∏–¥–∏—è –Ω–∞ GPU CC 6.1+)
# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º Piper (CPU) –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ GPU
current_voice_config = {
    "engine": "piper",
    "voice": "dmitri",  # lidia / dmitri / irina / lidia_openvoice
}

# –ü–∞–ø–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
TEMP_DIR = Path("./temp")
TEMP_DIR.mkdir(exist_ok=True)

# –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤ –∑–≤–æ–Ω–∫–æ–≤
CALLS_LOG_DIR = Path("./calls_log")
CALLS_LOG_DIR.mkdir(exist_ok=True)


class ConversationRequest(BaseModel):
    text: str
    session_id: Optional[str] = None


class TTSRequest(BaseModel):
    text: str
    language: str = "ru"


class OpenAISpeechRequest(BaseModel):
    """OpenAI-compatible TTS request for OpenWebUI integration"""
    model: str = "lidia-voice"
    input: str
    voice: str = "lidia"
    response_format: str = "wav"
    speed: float = 1.0


class ChatMessage(BaseModel):
    role: str
    content: str


class ChatCompletionRequest(BaseModel):
    """OpenAI-compatible chat completion request"""
    model: str = "lidia-secretary"
    messages: List[ChatMessage]
    stream: bool = False
    temperature: Optional[float] = None
    max_tokens: Optional[int] = None


@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    global voice_service, piper_service, openvoice_service, stt_service, llm_service, streaming_tts_manager

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ AI Secretary Orchestrator")

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Piper TTS (Dmitri, Irina) - CPU, –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–º
        logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ Piper TTS Service (CPU)...")
        try:
            piper_service = PiperTTSService()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Piper TTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            piper_service = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenVoice v2 (–õ–∏–¥–∏—è) - GPU CC 6.1+ (P104-100)
        if OPENVOICE_AVAILABLE:
            logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ OpenVoice TTS Service (GPU CC 6.1+)...")
            try:
                openvoice_service = OpenVoiceService()
                logger.info("‚úÖ OpenVoice v2 –∑–∞–≥—Ä—É–∂–µ–Ω (P104-100)")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è OpenVoice –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                openvoice_service = None
        else:
            logger.info("‚è≠Ô∏è OpenVoice –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)")
            openvoice_service = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è XTTS (–õ–∏–¥–∏—è) - GPU CC >= 7.0, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ Voice Clone Service (XTTS)...")
        try:
            voice_service = VoiceCloneService()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è XTTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Ç—Ä–µ–±—É–µ—Ç—Å—è GPU CC >= 7.0): {e}")
            voice_service = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM Service (vLLM –∏–ª–∏ Gemini)
        if LLM_BACKEND == "vllm" and VLLM_AVAILABLE:
            logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ vLLM LLM Service (Llama-3.1-8B)...")
            try:
                llm_service = VLLMLLMService()
                if llm_service.is_available():
                    logger.info("‚úÖ vLLM –ø–æ–¥–∫–ª—é—á–µ–Ω")
                else:
                    logger.warning("‚ö†Ô∏è vLLM –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º Gemini...")
                    llm_service = LLMService()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è vLLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({e}), –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini")
                llm_service = LLMService()
        else:
            logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ Gemini LLM Service...")
            llm_service = LLMService()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Streaming TTS Manager
        logger.info("üì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Streaming TTS Manager...")
        streaming_tts_manager = StreamingTTSManager(max_cache_size=50, cache_ttl=300)

        # STT –æ—Ç–∫–ª—é—á—ë–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ - –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞ –Ω–µ –Ω—É–∂–µ–Ω
        # –ú–æ–¥–µ–ª—å faster-whisper –∑–∞–≤–∏—Å–∞–µ—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
        logger.info("‚è≠Ô∏è STT –æ—Ç–∫–ª—é—á—ë–Ω (–¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞ –Ω–µ –Ω—É–∂–µ–Ω)")
        stt_service = None

        logger.info("‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        raise


@app.get("/")
async def root():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"""
    return {
        "status": "ok",
        "service": "AI Secretary Orchestrator",
        "endpoints": {
            "health": "/health",
            "process_call": "/process_call (POST)",
            "tts": "/tts (POST)",
            "stt": "/stt (POST)",
            "chat": "/chat (POST)",
        }
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø LLM —Å–µ—Ä–≤–∏—Å–∞
    llm_backend_type = "unknown"
    if llm_service:
        if hasattr(llm_service, 'api_url'):  # vLLM
            llm_backend_type = f"vllm ({llm_service.model_name})"
        elif hasattr(llm_service, 'model_name'):  # Gemini
            llm_backend_type = f"gemini ({llm_service.model_name})"

    services_status = {
        "voice_clone_xtts": voice_service is not None,
        "voice_clone_openvoice": openvoice_service is not None,
        "piper_tts": piper_service is not None,
        "stt": stt_service is not None,
        "llm": llm_service is not None,
        "llm_backend": llm_backend_type,
        "streaming_tts": streaming_tts_manager is not None,
    }

    # –î–ª—è health check –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª—é–±–æ–π TTS + llm
    any_tts = services_status["voice_clone_xtts"] or services_status["voice_clone_openvoice"] or services_status["piper_tts"]
    core_ok = any_tts and services_status["llm"]

    result = {
        "status": "healthy" if core_ok else "degraded",
        "services": services_status,
        "timestamp": datetime.now().isoformat()
    }

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É streaming TTS –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    if streaming_tts_manager is not None:
        result["streaming_tts_stats"] = streaming_tts_manager.get_stats()

    return result


def synthesize_with_current_voice(text: str, output_path: str, language: str = "ru"):
    """
    –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å —Å —Ç–µ–∫—É—â–∏–º –≤—ã–±—Ä–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç current_voice_config.

    Engines:
    - piper: CPU, –±—ã—Å—Ç—Ä—ã–π, –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–∞ (dmitri, irina)
    - openvoice: GPU CC 6.1+, –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ (lidia_openvoice)
    - xtts: GPU CC >= 7.0, –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (lidia)
    """
    engine = current_voice_config["engine"]
    voice = current_voice_config["voice"]

    if engine == "piper" and piper_service:
        logger.info(f"üéôÔ∏è Piper —Å–∏–Ω—Ç–µ–∑ ({voice}): '{text[:40]}...'")
        piper_service.synthesize_to_file(text, output_path, voice=voice)
    elif engine == "openvoice" and openvoice_service:
        logger.info(f"üéôÔ∏è OpenVoice —Å–∏–Ω—Ç–µ–∑ (–õ–∏–¥–∏—è): '{text[:40]}...'")
        openvoice_service.synthesize_to_file(text, output_path, language=language)
    elif engine == "xtts" and voice_service:
        logger.info(f"üéôÔ∏è XTTS —Å–∏–Ω—Ç–µ–∑ (–õ–∏–¥–∏—è): '{text[:40]}...'")
        voice_service.synthesize_to_file(text, output_path, language=language)
    elif voice_service:
        # Fallback to XTTS if available
        logger.info(f"üéôÔ∏è XTTS —Å–∏–Ω—Ç–µ–∑ (fallback): '{text[:40]}...'")
        voice_service.synthesize_to_file(text, output_path, language=language)
    elif openvoice_service:
        # Fallback to OpenVoice if XTTS not available
        logger.info(f"üéôÔ∏è OpenVoice —Å–∏–Ω—Ç–µ–∑ (fallback): '{text[:40]}...'")
        openvoice_service.synthesize_to_file(text, output_path, language=language)
    elif piper_service:
        # Fallback to Piper
        logger.info(f"üéôÔ∏è Piper —Å–∏–Ω—Ç–µ–∑ (fallback): '{text[:40]}...'")
        piper_service.synthesize_to_file(text, output_path, voice="irina")
    else:
        raise RuntimeError("No TTS service available")


@app.post("/tts")
async def text_to_speech(request: TTSRequest):
    """
    –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å —Ç–µ–∫—É—â–∏–º –≤—ã–±—Ä–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º
    """
    if not voice_service and not piper_service:
        raise HTTPException(status_code=503, detail="No TTS service initialized")

    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        output_file = TEMP_DIR / f"tts_{datetime.now().timestamp()}.wav"

        # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Å —Ç–µ–∫—É—â–∏–º –≥–æ–ª–æ—Å–æ–º
        synthesize_with_current_voice(
            text=request.text,
            output_path=str(output_file),
            language=request.language
        )

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∞–π–ª
        return FileResponse(
            path=output_file,
            media_type="audio/wav",
            filename="response.wav"
        )

    except Exception as e:
        logger.error(f"‚ùå TTS Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/stt")
async def speech_to_text(audio: UploadFile = File(...)):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
    """
    if not stt_service:
        raise HTTPException(status_code=503, detail="STT service not initialized")

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_audio = TEMP_DIR / f"stt_{datetime.now().timestamp()}_{audio.filename}"

        with open(temp_audio, "wb") as f:
            content = await audio.read()
            f.write(content)

        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º
        result = stt_service.transcribe(temp_audio, language="ru")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_audio.unlink()

        return {
            "text": result["text"],
            "language": result["language"],
            "segments_count": len(result.get("segments", []))
        }

    except Exception as e:
        logger.error(f"‚ùå STT Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chat")
async def chat(request: ConversationRequest):
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM (Gemini)
    """
    if not llm_service:
        raise HTTPException(status_code=503, detail="LLM service not initialized")

    try:
        response = llm_service.generate_response(request.text)

        return {
            "response": response,
            "session_id": request.session_id
        }

    except Exception as e:
        logger.error(f"‚ùå LLM Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/process_call")
async def process_call(audio: UploadFile = File(...)):
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–≤–æ–Ω–∫–∞:
    1. STT - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
    2. LLM - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    3. TTS - —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞—É–¥–∏–æ —Å –æ—Ç–≤–µ—Ç–æ–º —Å–µ–∫—Ä–µ—Ç–∞—Ä—è
    """
    call_id = f"call_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    logger.info(f"üìû –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–≤–æ–Ω–∫–∞ {call_id}")

    try:
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥—è—â–∏–π –∞—É–¥–∏–æ
        input_audio = CALLS_LOG_DIR / f"{call_id}_input.wav"
        with open(input_audio, "wb") as f:
            content = await audio.read()
            f.write(content)

        # 2. –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å (STT)
        logger.info(f"üéß STT –¥–ª—è {call_id}")
        stt_result = stt_service.transcribe(input_audio, language="ru")
        recognized_text = stt_result["text"]
        logger.info(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {recognized_text}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        with open(CALLS_LOG_DIR / f"{call_id}_transcript.txt", "w") as f:
            f.write(f"USER: {recognized_text}\n")

        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (LLM)
        logger.info(f"ü§ñ LLM –¥–ª—è {call_id}")
        llm_response = llm_service.generate_response(recognized_text)
        logger.info(f"üí¨ –û—Ç–≤–µ—Ç: {llm_response}")

        # –î–æ–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        with open(CALLS_LOG_DIR / f"{call_id}_transcript.txt", "a") as f:
            f.write(f"ASSISTANT: {llm_response}\n")

        # 4. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (TTS)
        logger.info(f"üéôÔ∏è  TTS –¥–ª—è {call_id}")
        output_audio = CALLS_LOG_DIR / f"{call_id}_output.wav"
        voice_service.synthesize_to_file(
            text=llm_response,
            output_path=str(output_audio),
            language="ru"
        )

        logger.info(f"‚úÖ –ó–≤–æ–Ω–æ–∫ {call_id} –æ–±—Ä–∞–±–æ—Ç–∞–Ω")

        # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—É–¥–∏–æ –æ—Ç–≤–µ—Ç
        return FileResponse(
            path=output_audio,
            media_type="audio/wav",
            filename=f"{call_id}_response.wav",
            headers={
                "X-Call-ID": call_id,
                "X-Recognized-Text": recognized_text,
                "X-Response-Text": llm_response
            }
        )

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–≤–æ–Ω–∫–∞ {call_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/reset_conversation")
async def reset_conversation():
    """–°–±—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
    if llm_service:
        llm_service.reset_conversation()
        return {"status": "ok", "message": "Conversation history reset"}
    raise HTTPException(status_code=503, detail="LLM service not initialized")


# ============== OpenAI-Compatible Endpoints for OpenWebUI ==============

@app.get("/v1/models")
@app.get("/v1/models/")
async def list_models():
    """OpenAI-compatible models list for OpenWebUI"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è backend-–∞ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
    if llm_service and hasattr(llm_service, 'api_url'):
        # vLLM backend - –ø—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
        model_name = getattr(llm_service, 'model_name', 'unknown')
        if model_name == "lydia" or "qwen" in model_name.lower():
            backend_name = "vLLM Qwen2.5-7B + Lydia LoRA"
        elif "llama" in model_name.lower():
            backend_name = "vLLM Llama-3.1-8B"
        else:
            backend_name = f"vLLM {model_name}"
    else:
        backend_name = "Gemini"

    return {
        "object": "list",
        "data": [
            {
                "id": "lidia-secretary",
                "object": "model",
                "created": 1700000000,
                "owned_by": "ai-secretary",
                "permission": [],
                "root": "lidia-secretary",
                "parent": None,
                "description": f"–õ–∏–¥–∏—è - —Ü–∏—Ñ—Ä–æ–≤–æ–π —Å–µ–∫—Ä–µ—Ç–∞—Ä—å ({backend_name})"
            }
        ]
    }


@app.get("/v1/voices")
async def list_voices():
    """List available voices"""
    return {
        "voices": [
            {"voice_id": "lidia", "name": "–õ–∏–¥–∏—è", "language": "ru"}
        ]
    }


@app.post("/v1/audio/speech")
async def openai_speech(request: OpenAISpeechRequest):
    """
    OpenAI-compatible TTS endpoint for OpenWebUI integration
    POST /v1/audio/speech

    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫—ç—à streaming TTS manager.
    –ï—Å–ª–∏ –∞—É–¥–∏–æ —É–∂–µ –±—ã–ª–æ –ø—Ä–µ–¥—Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–æ –≤–æ –≤—Ä–µ–º—è streaming LLM - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ.
    """
    if not voice_service and not piper_service:
        raise HTTPException(status_code=503, detail="No TTS service initialized")

    try:
        output_file = TEMP_DIR / f"speech_{datetime.now().timestamp()}.wav"
        start_time = time.time()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à streaming TTS (—Ç–æ–ª—å–∫–æ –¥–ª—è XTTS)
        cached_audio = None
        if current_voice_config["engine"] == "xtts" and streaming_tts_manager is not None:
            cached_audio = streaming_tts_manager.get_cached_audio(request.input)

        if cached_audio is not None:
            # Cache HIT - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
            audio_data, sample_rate = cached_audio
            sf.write(str(output_file), audio_data, sample_rate)
            elapsed = time.time() - start_time
            logger.info(f"‚ö° TTS –∏–∑ –∫—ç—à–∞ –∑–∞ {elapsed:.3f}s (vs ~5-10s –æ–±—ã—á–Ω—ã–π —Å–∏–Ω—Ç–µ–∑)")
        else:
            # Cache MISS - —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Å —Ç–µ–∫—É—â–∏–º –≥–æ–ª–æ—Å–æ–º
            synthesize_with_current_voice(
                text=request.input,
                output_path=str(output_file),
                language="ru"
            )
            elapsed = time.time() - start_time
            logger.info(f"üéôÔ∏è TTS —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω –∑–∞ {elapsed:.2f}s")

        return FileResponse(
            path=output_file,
            media_type="audio/wav",
            filename="speech.wav"
        )

    except Exception as e:
        logger.error(f"‚ùå OpenAI TTS Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest):
    """
    OpenAI-compatible chat completions endpoint for OpenWebUI
    Supports both streaming and non-streaming responses.
    –ü—Ä–∏ streaming - –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ TTS –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º.
    """
    if not llm_service:
        raise HTTPException(status_code=503, detail="LLM service not initialized")

    logger.info(f"üí¨ Chat completions request: stream={request.stream}, messages={len(request.messages)}")

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Pydantic –º–æ–¥–µ–ª–∏ –≤ dict
    messages = [{"role": m.role, "content": m.content} for m in request.messages]

    if request.stream:
        # Streaming response (SSE) —Å —Ñ–æ–Ω–æ–≤—ã–º —Å–∏–Ω—Ç–µ–∑–æ–º TTS
        async def generate_stream():
            created = int(time.time())
            chunk_id = f"chatcmpl-{created}"
            session_id = f"tts-{created}"

            # –ù–∞—á–∏–Ω–∞–µ–º —Å–µ—Å—Å–∏—é streaming TTS –µ—Å–ª–∏ —Å–µ—Ä–≤–∏—Å—ã –¥–æ—Å—Ç—É–ø–Ω—ã
            use_streaming_tts = (
                streaming_tts_manager is not None and
                voice_service is not None
            )

            if use_streaming_tts:
                streaming_tts_manager.start_session(session_id)
                logger.info(f"üé¨ Streaming TTS –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")

            try:
                for text_chunk in llm_service.generate_response_from_messages(messages, stream=True):
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º chunk –∫–ª–∏–µ–Ω—Ç—É
                    chunk_data = {
                        "id": chunk_id,
                        "object": "chat.completion.chunk",
                        "created": created,
                        "model": request.model,
                        "choices": [{
                            "index": 0,
                            "delta": {"content": text_chunk},
                            "finish_reason": None
                        }]
                    }
                    yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"

                    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º chunk –≤ streaming TTS manager
                    if use_streaming_tts and text_chunk:
                        streaming_tts_manager.add_text_chunk(
                            session_id, text_chunk, voice_service
                        )

                # Final chunk
                final_chunk = {
                    "id": chunk_id,
                    "object": "chat.completion.chunk",
                    "created": created,
                    "model": request.model,
                    "choices": [{
                        "index": 0,
                        "delta": {},
                        "finish_reason": "stop"
                    }]
                }
                yield f"data: {json.dumps(final_chunk)}\n\n"
                yield "data: [DONE]\n\n"

                # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–µ—Å—Å–∏—é TTS (—Å–∫–ª–µ–∏–≤–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ)
                if use_streaming_tts:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å response
                    threading.Thread(
                        target=streaming_tts_manager.finish_session,
                        args=(session_id, voice_service),
                        daemon=True
                    ).start()

            except Exception as e:
                logger.error(f"‚ùå Streaming error: {e}")
                error_chunk = {
                    "error": {"message": str(e), "type": "server_error"}
                }
                yield f"data: {json.dumps(error_chunk)}\n\n"

        return StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            }
        )
    else:
        # Non-streaming response
        try:
            response_text = llm_service.generate_response_from_messages(messages, stream=False)

            # Consume generator if it returns one
            if hasattr(response_text, '__iter__') and not isinstance(response_text, str):
                response_text = "".join(response_text)

            return {
                "id": f"chatcmpl-{int(time.time())}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": request.model,
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": response_text
                    },
                    "finish_reason": "stop"
                }],
                "usage": {
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                }
            }
        except Exception as e:
            logger.error(f"‚ùå Chat completions error: {e}")
            raise HTTPException(status_code=500, detail=str(e))


# ============== Admin Web Interface ==============

@app.get("/admin")
@app.get("/admin/")
async def admin_web_interface():
    """–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∞–¥–º–∏–Ω–∫–∏"""
    from fastapi.responses import HTMLResponse

    admin_html_path = Path(__file__).parent / "admin_web.html"
    if admin_html_path.exists():
        return HTMLResponse(content=admin_html_path.read_text(encoding='utf-8'))
    else:
        return HTMLResponse(content="""
            <html><body style="background:#1a1a2e;color:#eee;font-family:sans-serif;padding:50px;text-align:center">
            <h1>Admin Web Interface</h1>
            <p>File admin_web.html not found</p>
            <p><a href="/admin/status" style="color:#e94560">API Status</a></p>
            </body></html>
        """)


# ============== Admin API Endpoints ==============

class AdminTTSPresetRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ—Å–µ—Ç–∞ TTS"""
    preset: str  # warm, calm, energetic, natural, neutral


class AdminLLMPromptRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
    prompt: str


class AdminLLMModelRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ LLM"""
    model: str  # gemini-2.5-flash, gemini-2.5-pro


class AdminTTSTestRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑"""
    text: str
    preset: str = "natural"


@app.get("/admin/status")
async def admin_status():
    """–ü–æ–ª–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –∞–¥–º–∏–Ω–∫–∏"""
    import torch

    status = {
        "orchestrator": "running",
        "services": {
            "voice_clone": voice_service is not None,
            "llm": llm_service is not None,
            "stt": stt_service is not None,
            "streaming_tts": streaming_tts_manager is not None,
            "piper_tts": piper_service is not None,
        },
        "gpu": None,
        "streaming_tts_stats": None,
        "llm_config": None,
        "tts_config": None,
    }

    # GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    if torch.cuda.is_available():
        gpu_info = []
        for i in range(torch.cuda.device_count()):
            try:
                name = torch.cuda.get_device_name(i)
                total = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                allocated = torch.cuda.memory_allocated(i) / (1024**3)
                gpu_info.append({
                    "id": i,
                    "name": name,
                    "total_gb": round(total, 2),
                    "used_gb": round(allocated, 2),
                })
            except Exception:
                pass
        status["gpu"] = gpu_info

    # Streaming TTS —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if streaming_tts_manager:
        status["streaming_tts_stats"] = streaming_tts_manager.get_stats()

    # LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    if llm_service:
        if hasattr(llm_service, 'get_config'):
            status["llm_config"] = llm_service.get_config()
        else:
            # –î–ª—è vLLM –∏ –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –±–µ–∑ get_config
            status["llm_config"] = {
                "model_name": getattr(llm_service, 'model_name', 'unknown'),
                "api_url": getattr(llm_service, 'api_url', None),
                "backend": "vllm" if hasattr(llm_service, 'api_url') else "gemini",
            }

    # TTS –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    if voice_service:
        status["tts_config"] = {
            "device": voice_service.device,
            "default_preset": voice_service.default_preset,
            "samples_count": len(voice_service.voice_samples),
            "cache_dir": str(voice_service.cache_dir),
        }

    return status


@app.get("/admin/tts/presets")
async def admin_tts_presets():
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö TTS –ø—Ä–µ—Å–µ—Ç–æ–≤"""
    from voice_clone_service import INTONATION_PRESETS

    presets = {}
    for name, preset in INTONATION_PRESETS.items():
        presets[name] = {
            "display_name": preset.name,
            "temperature": preset.temperature,
            "repetition_penalty": preset.repetition_penalty,
            "top_k": preset.top_k,
            "top_p": preset.top_p,
            "speed": preset.speed,
        }

    current = voice_service.default_preset if voice_service else "natural"

    return {
        "presets": presets,
        "current": current,
    }


@app.post("/admin/tts/preset")
async def admin_set_tts_preset(request: AdminTTSPresetRequest):
    """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–µ—Å–µ—Ç TTS"""
    from voice_clone_service import INTONATION_PRESETS

    if request.preset not in INTONATION_PRESETS:
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–µ—Å–µ—Ç: {request.preset}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(INTONATION_PRESETS.keys())}"
        )

    if voice_service:
        voice_service.default_preset = request.preset
        preset = INTONATION_PRESETS[request.preset]
        return {
            "status": "ok",
            "preset": request.preset,
            "display_name": preset.name,
            "settings": {
                "temperature": preset.temperature,
                "speed": preset.speed,
            }
        }

    raise HTTPException(status_code=503, detail="Voice service not initialized")


@app.post("/admin/tts/test")
async def admin_tts_test(request: AdminTTSTestRequest):
    """–¢–µ—Å—Ç–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏"""
    if not voice_service:
        raise HTTPException(status_code=503, detail="Voice service not initialized")

    try:
        import time as t
        start = t.time()

        output_file = TEMP_DIR / f"admin_test_{datetime.now().timestamp()}.wav"
        voice_service.synthesize_to_file(
            text=request.text,
            output_path=str(output_file),
            preset=request.preset,
            language="ru"
        )

        elapsed = t.time() - start

        # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
        import wave
        with wave.open(str(output_file), 'rb') as wf:
            frames = wf.getnframes()
            rate = wf.getframerate()
            duration = frames / float(rate)

        return {
            "status": "ok",
            "file": str(output_file),
            "duration_sec": round(duration, 2),
            "synthesis_time_sec": round(elapsed, 2),
            "rtf": round(elapsed / duration, 2) if duration > 0 else 0,
        }

    except Exception as e:
        logger.error(f"‚ùå Admin TTS test error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/admin/tts/cache")
async def admin_tts_cache():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞ streaming TTS"""
    if streaming_tts_manager:
        return streaming_tts_manager.get_stats()
    return {"cache_size": 0, "active_sessions": 0}


@app.delete("/admin/tts/cache")
async def admin_clear_tts_cache():
    """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à streaming TTS"""
    if streaming_tts_manager:
        with streaming_tts_manager._cache_lock:
            count = len(streaming_tts_manager._cache)
            streaming_tts_manager._cache.clear()
        return {"status": "ok", "cleared_items": count}
    return {"status": "ok", "cleared_items": 0}


@app.get("/admin/llm/prompt")
async def admin_get_llm_prompt():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç LLM"""
    if llm_service:
        return {
            "prompt": llm_service.system_prompt,
            "model": llm_service.model_name,
        }
    raise HTTPException(status_code=503, detail="LLM service not initialized")


@app.post("/admin/llm/prompt")
async def admin_set_llm_prompt(request: AdminLLMPromptRequest):
    """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç LLM"""
    if llm_service:
        llm_service.set_system_prompt(request.prompt)
        return {
            "status": "ok",
            "prompt": request.prompt[:100] + "..." if len(request.prompt) > 100 else request.prompt,
        }
    raise HTTPException(status_code=503, detail="LLM service not initialized")


@app.get("/admin/llm/model")
async def admin_get_llm_model():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å LLM"""
    if llm_service:
        return {"model": llm_service.model_name}
    raise HTTPException(status_code=503, detail="LLM service not initialized")


@app.post("/admin/llm/model")
async def admin_set_llm_model(request: AdminLLMModelRequest):
    """–ò–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å LLM"""
    allowed_models = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"]

    if request.model not in allowed_models:
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {request.model}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {allowed_models}"
        )

    if llm_service:
        try:
            llm_service.set_model(request.model)
            return {"status": "ok", "model": request.model}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    raise HTTPException(status_code=503, detail="LLM service not initialized")


@app.delete("/admin/llm/history")
async def admin_clear_llm_history():
    """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ LLM"""
    if llm_service:
        count = len(llm_service.conversation_history)
        llm_service.reset_conversation()
        return {"status": "ok", "cleared_messages": count}
    raise HTTPException(status_code=503, detail="LLM service not initialized")


@app.get("/admin/llm/history")
async def admin_get_llm_history():
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ LLM"""
    if llm_service:
        return {
            "history": llm_service.conversation_history,
            "count": len(llm_service.conversation_history),
        }
    raise HTTPException(status_code=503, detail="LLM service not initialized")


# ============== Voice Selection API ==============

class AdminVoiceRequest(BaseModel):
    voice: str  # lidia / dmitri / irina


@app.get("/admin/voices")
async def admin_get_voices():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤"""
    voices = []

    # XTTS –≥–æ–ª–æ—Å (–õ–∏–¥–∏—è) - —Ç—Ä–µ–±—É–µ—Ç GPU CC >= 7.0
    if voice_service:
        voices.append({
            "id": "lidia",
            "name": "–õ–∏–¥–∏—è (XTTS)",
            "engine": "xtts",
            "description": "–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å (XTTS v2, GPU CC >= 7.0)",
            "available": True,
            "samples_count": len(voice_service.voice_samples),
        })

    # OpenVoice –≥–æ–ª–æ—Å (–õ–∏–¥–∏—è) - —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ GPU CC 6.1+
    if openvoice_service:
        voices.append({
            "id": "lidia_openvoice",
            "name": "–õ–∏–¥–∏—è (OpenVoice)",
            "engine": "openvoice",
            "description": "–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å (OpenVoice v2, GPU CC 6.1+)",
            "available": True,
            "samples_count": len(openvoice_service.voice_samples) if openvoice_service.voice_samples else 0,
        })

    # Piper –≥–æ–ª–æ—Å–∞ (CPU)
    if piper_service:
        piper_voices = piper_service.get_available_voices()
        for voice_id, info in piper_voices.items():
            voices.append({
                "id": voice_id,
                "name": info["name"],
                "engine": "piper",
                "description": info["description"],
                "available": info["available"],
            })

    return {
        "voices": voices,
        "current": current_voice_config,
    }


@app.get("/admin/voice")
async def admin_get_current_voice():
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å"""
    return current_voice_config


@app.post("/admin/voice")
async def admin_set_voice(request: AdminVoiceRequest):
    """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π –≥–æ–ª–æ—Å"""
    global current_voice_config

    voice_id = request.voice.lower()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–∞
    if voice_id == "lidia":
        if not voice_service:
            raise HTTPException(status_code=503, detail="XTTS service not available (requires GPU CC >= 7.0)")
        current_voice_config = {"engine": "xtts", "voice": "lidia"}
        logger.info(f"üé§ –ì–æ–ª–æ—Å –∏–∑–º–µ–Ω—ë–Ω –Ω–∞: –õ–∏–¥–∏—è (XTTS)")

    elif voice_id == "lidia_openvoice":
        if not openvoice_service:
            raise HTTPException(status_code=503, detail="OpenVoice service not available")
        current_voice_config = {"engine": "openvoice", "voice": "lidia_openvoice"}
        logger.info(f"üé§ –ì–æ–ª–æ—Å –∏–∑–º–µ–Ω—ë–Ω –Ω–∞: –õ–∏–¥–∏—è (OpenVoice)")

    elif voice_id in ["dmitri", "irina"]:
        if not piper_service:
            raise HTTPException(status_code=503, detail="Piper TTS service not available")
        piper_voices = piper_service.get_available_voices()
        if voice_id not in piper_voices or not piper_voices[voice_id]["available"]:
            raise HTTPException(status_code=400, detail=f"Voice model not found: {voice_id}")
        current_voice_config = {"engine": "piper", "voice": voice_id}
        logger.info(f"üé§ –ì–æ–ª–æ—Å –∏–∑–º–µ–Ω—ë–Ω –Ω–∞: {piper_voices[voice_id]['name']} (Piper)")

    else:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown voice: {voice_id}. Available: lidia, lidia_openvoice, dmitri, irina"
        )

    return {"status": "ok", **current_voice_config}


@app.post("/admin/voice/test")
async def admin_test_voice(request: AdminVoiceRequest):
    """–¢–µ—Å—Ç–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–º"""
    voice_id = request.voice.lower()
    test_text = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–æ–ª–æ—Å–∞."

    output_path = TEMP_DIR / f"voice_test_{voice_id}_{int(time.time())}.wav"

    try:
        if voice_id == "lidia":
            if not voice_service:
                raise HTTPException(status_code=503, detail="XTTS not available (requires GPU CC >= 7.0)")
            voice_service.synthesize_to_file(test_text, str(output_path), preset="natural")

        elif voice_id == "lidia_openvoice":
            if not openvoice_service:
                raise HTTPException(status_code=503, detail="OpenVoice not available")
            openvoice_service.synthesize_to_file(test_text, str(output_path), language="ru")

        elif voice_id in ["dmitri", "irina"]:
            if not piper_service:
                raise HTTPException(status_code=503, detail="Piper not available")
            piper_service.synthesize_to_file(test_text, str(output_path), voice=voice_id)

        else:
            raise HTTPException(status_code=400, detail=f"Unknown voice: {voice_id}. Available: lidia, lidia_openvoice, dmitri, irina")

        return FileResponse(
            output_path,
            media_type="audio/wav",
            filename=f"test_{voice_id}.wav"
        )

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def get_current_tts_service():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π TTS —Å–µ—Ä–≤–∏—Å –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    engine = current_voice_config["engine"]
    voice = current_voice_config["voice"]

    if engine == "xtts":
        return voice_service, {"preset": "natural"}
    elif engine == "piper":
        return piper_service, {"voice": voice}
    else:
        return voice_service, {"preset": "natural"}


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    port = int(os.getenv("ORCHESTRATOR_PORT", 8002))
    logger.info(f"üéØ –ó–∞–ø—É—Å–∫ Orchestrator –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    uvicorn.run(
        "orchestrator:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        log_level="info"
    )
